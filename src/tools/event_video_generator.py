"""
Event Video Generator - åŸºäºH5äº‹ä»¶æ•°æ®ç”Ÿæˆå¯è§†åŒ–è§†é¢‘

åŸºäºLinuså“²å­¦ï¼š
- æ•°æ®ç»“æ„æ­£ç¡®: Events (N,4) â†’ Time Windows â†’ RGB Frames â†’ Video
- æ¶ˆé™¤ç‰¹æ®Šæƒ…å†µ: ç»Ÿä¸€2.5msæ—¶é—´çª—å£ï¼Œç™½èƒŒæ™¯+çº¢è“æ˜ å°„
- å®ç”¨ä¸»ä¹‰: è§£å†³H5äº‹ä»¶æ•°æ®å¯è§†åŒ–çš„å®é™…éœ€æ±‚

Usage:
    python src/tools/event_video_generator.py \
        --input "path/to/events.h5" \
        --output "output_video.mp4" \
        --frame_duration_ms 2.5
"""

import numpy as np
import h5py
import cv2
import argparse
from pathlib import Path
import os
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„ä»¥å¯¼å…¥ç°æœ‰æ¨¡å—
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.data_processing.encode import load_h5_events


class EventVideoGenerator:
    """H5äº‹ä»¶æ•°æ®è§†é¢‘ç”Ÿæˆå™¨"""
    
    def __init__(self, sensor_size=(480, 640), frame_duration_ms=2.5, fps=30):
        """
        Args:
            sensor_size: ä¼ æ„Ÿå™¨å°ºå¯¸ (height, width)
            frame_duration_ms: æ¯å¸§æ—¶é—´é—´éš” (é»˜è®¤2.5ms)
            fps: è¾“å‡ºè§†é¢‘å¸§ç‡
        """
        self.sensor_size = sensor_size  # (H, W)
        self.frame_duration_us = frame_duration_ms * 1000  # è½¬æ¢ä¸ºå¾®ç§’
        self.fps = fps
        
    def load_events(self, h5_path: str) -> np.ndarray:
        """åŠ è½½H5äº‹ä»¶æ•°æ®"""
        print(f"Loading events from: {h5_path}")
        events_np = load_h5_events(h5_path)
        print(f"Loaded {len(events_np):,} events")
        
        # æ—¶é—´èŒƒå›´ç»Ÿè®¡
        if len(events_np) > 0:
            t_min, t_max = events_np[:, 0].min(), events_np[:, 0].max()
            duration_ms = (t_max - t_min) / 1000
            print(f"Time range: {t_min:.0f} - {t_max:.0f} Î¼s ({duration_ms:.1f} ms)")
        
        return events_np
    
    def _create_event_visualization_iebcs(self, events: np.ndarray) -> np.ndarray:
        """åˆ›å»ºIEBCSäº‹ä»¶å¯è§†åŒ– - ç™½èƒŒæ™¯ç‰ˆæœ¬"""
        # ğŸ¯ å…³é”®ï¼šåˆ›å»ºç™½è‰²èƒŒæ™¯çš„RGBå›¾åƒ
        event_img = np.full((*self.sensor_size, 3), 255, dtype=np.uint8)  # ç™½è‰²èƒŒæ™¯
        
        # ğŸ¨ æ ¸å¿ƒé¢œè‰²æ˜ å°„é€»è¾‘
        for event in events:
            x, y, pol = int(event[1]), int(event[2]), int(event[3])
            if 0 <= x < self.sensor_size[1] and 0 <= y < self.sensor_size[0]:
                if pol > 0.5:  # Positive event (ON)
                    event_img[y, x] = [0, 0, 255]  # ğŸ”´ Red (RGBæ ¼å¼)
                else:  # Negative event (OFF)  
                    event_img[y, x] = [255, 0, 0]  # ğŸ”µ Blue (RGBæ ¼å¼)
        
        return event_img
    
    def generate_frames(self, events_np: np.ndarray):
        """ç”Ÿæˆè§†é¢‘å¸§åºåˆ—"""
        if len(events_np) == 0:
            print("No events to generate frames")
            return []
            
        # è®¡ç®—æ—¶é—´èŒƒå›´å’Œå¸§æ•°
        t_min, t_max = events_np[:, 0].min(), events_np[:, 0].max()
        total_duration = t_max - t_min
        num_frames = int(np.ceil(total_duration / self.frame_duration_us))
        
        print(f"Generating {num_frames} frames with {self.frame_duration_us/1000:.1f}ms per frame")
        
        frames = []
        
        for frame_idx in range(num_frames):
            # è®¡ç®—å½“å‰å¸§çš„æ—¶é—´çª—å£
            t_start = t_min + frame_idx * self.frame_duration_us
            t_end = t_start + self.frame_duration_us
            
            # é€‰æ‹©å½“å‰æ—¶é—´çª—å£å†…çš„äº‹ä»¶
            mask = (events_np[:, 0] >= t_start) & (events_np[:, 0] < t_end)
            frame_events = events_np[mask]
            
            # ç”Ÿæˆå¯è§†åŒ–å›¾åƒ
            frame_img = self._create_event_visualization_iebcs(frame_events)
            frames.append(frame_img)
            
            # è¿›åº¦æ˜¾ç¤º
            if (frame_idx + 1) % 100 == 0 or frame_idx == num_frames - 1:
                progress = (frame_idx + 1) / num_frames * 100
                print(f"Generated frame {frame_idx + 1}/{num_frames} ({progress:.1f}%) - {len(frame_events)} events")
        
        return frames
    
    def save_video(self, frames: list, output_path: str):
        """ä¿å­˜è§†é¢‘æ–‡ä»¶"""
        if not frames:
            print("No frames to save")
            return
            
        print(f"Saving video to: {output_path}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®è§†é¢‘ç¼–ç å™¨
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        video_writer = cv2.VideoWriter(
            str(output_path), 
            fourcc, 
            self.fps, 
            (self.sensor_size[1], self.sensor_size[0])  # OpenCV expects (width, height)
        )
        
        # å†™å…¥å¸§
        for frame_idx, frame in enumerate(frames):
            # OpenCVä½¿ç”¨BGRæ ¼å¼ï¼Œéœ€è¦è½¬æ¢
            frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
            video_writer.write(frame_bgr)
            
            if (frame_idx + 1) % 100 == 0 or frame_idx == len(frames) - 1:
                progress = (frame_idx + 1) / len(frames) * 100
                print(f"Saved frame {frame_idx + 1}/{len(frames)} ({progress:.1f}%)")
        
        video_writer.release()
        print(f"âœ… Video saved successfully: {output_path}")
        
        # è¾“å‡ºè§†é¢‘ä¿¡æ¯
        file_size_mb = output_path.stat().st_size / (1024 * 1024)
        duration_s = len(frames) / self.fps
        print(f"ğŸ“Š Video info: {len(frames)} frames, {duration_s:.1f}s, {file_size_mb:.1f}MB")
    
    def process_h5_file(self, h5_path: str, output_path: str = None, output_dir: str = "debug_output"):
        """å¤„ç†å•ä¸ªH5æ–‡ä»¶ç”Ÿæˆè§†é¢‘"""
        # ç”Ÿæˆé»˜è®¤è¾“å‡ºè·¯å¾„ï¼ˆåŒ…å«æ–‡ä»¶åï¼‰
        if output_path is None:
            h5_file = Path(h5_path)
            output_dir = Path(output_dir)
            output_dir.mkdir(exist_ok=True)
            output_path = output_dir / f"{h5_file.stem}_visualization.mp4"
        
        print(f"ğŸ¬ Event Video Generation Started")
        print(f"ğŸ“ Input: {h5_path}")
        print(f"ğŸ“ Output: {output_path}")
        print(f"âš™ï¸ Config: {self.sensor_size}, {self.frame_duration_us/1000:.1f}ms/frame, {self.fps}fps")
        print("-" * 60)
        
        # åŠ è½½äº‹ä»¶æ•°æ®
        events_np = self.load_events(h5_path)
        
        if len(events_np) == 0:
            print("âŒ No events found in H5 file")
            return
        
        # ç”Ÿæˆå¸§åºåˆ—
        frames = self.generate_frames(events_np)
        
        if not frames:
            print("âŒ No frames generated")
            return
            
        # ä¿å­˜è§†é¢‘
        self.save_video(frames, output_path)
        
        print("-" * 60)
        print(f"ğŸ‰ Video generation completed!")


def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(description="Generate visualization video from H5 event data")
    
    # é»˜è®¤è·¯å¾„ï¼ˆWindowsæ ¼å¼ï¼ŒPythonä¼šè‡ªåŠ¨å¤„ç†ï¼‰
    default_input = r"E:\2025\event_flick_flare\Unet_main\data_simu\physics_method\background_with_flare_events_testoutput\composed_00504_bg_flare.h5"
    
    parser.add_argument("--input", "-i", default=default_input,
                       help="Input H5 event file path")
    parser.add_argument("--output", "-o", default=None,
                       help="Output video file path (auto-generated if not specified)")
    parser.add_argument("--output_dir", default="debug_output",
                       help="Output directory (default: debug_output)")
    parser.add_argument("--frame_duration_ms", "-d", type=float, default=2.5,
                       help="Frame duration in milliseconds (default: 2.5ms)")
    parser.add_argument("--fps", type=int, default=10,
                       help="Output video FPS (default: 10)")
    parser.add_argument("--sensor_size", nargs=2, type=int, default=[480, 640],
                       help="Sensor size as height width (default: 480 640)")
    
    args = parser.parse_args()
    
    # è½¬æ¢Windowsè·¯å¾„æ ¼å¼
    input_path = args.input.replace('\\', '/')
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_path):
        print(f"âŒ Input file not found: {input_path}")
        return
    
    # åˆ›å»ºè§†é¢‘ç”Ÿæˆå™¨
    generator = EventVideoGenerator(
        sensor_size=tuple(args.sensor_size),
        frame_duration_ms=args.frame_duration_ms,
        fps=args.fps
    )
    
    # å¤„ç†æ–‡ä»¶
    generator.process_h5_file(input_path, args.output, args.output_dir)


if __name__ == "__main__":
    main()