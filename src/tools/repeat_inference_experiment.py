#!/usr/bin/env python3
"""
é€’å½’æ¨ç†å®éªŒå·¥å…· - éªŒè¯UNet3Dç½‘ç»œçš„é€’å½’å¤„ç†æ•ˆæœ

åŸºäºLinuså“²å­¦ï¼š
- æ•°æ®ç»“æ„æ­£ç¡®: Input H5 â†’ UNet â†’ Output1 â†’ UNet â†’ Output2 â†’ ... â†’ OutputN
- æ¶ˆé™¤ç‰¹æ®Šæƒ…å†µ: ç»Ÿä¸€é€’å½’å¤„ç†pipelineï¼Œæ— éœ€æ‰‹åŠ¨ç®¡ç†ä¸­é—´æ­¥éª¤
- å®ç”¨ä¸»ä¹‰: è§‚å¯Ÿç½‘ç»œé€’å½’å¤„ç†å¯¹äº‹ä»¶æ•°æ®çš„ç´¯ç§¯å½±å“

ç”¨æ³•:
    python src/tools/repeat_inference_experiment.py --iterations 10
    python src/tools/repeat_inference_experiment.py --iterations 5 --debug
    
åŠŸèƒ½:
- å¯¹æŒ‡å®šçš„ä¸¤ä¸ªH5æ–‡ä»¶è¿›è¡Œé€’å½’inferenceå¤„ç†
- æ¯æ¬¡è¾“å‡ºä½œä¸ºä¸‹æ¬¡è¾“å…¥ï¼Œå½¢æˆå¤„ç†é“¾
- æ¯ä¸ªä¸­é—´ç»“æœç”ŸæˆMP4è§†é¢‘
- è¾“å‡ºæ•´ç†åˆ°debug_output/repeat/æ–‡ä»¶å¤¹
- åˆ†æé€’å½’å¤„ç†è¿‡ç¨‹ä¸­äº‹ä»¶æ•°é‡å’Œåˆ†å¸ƒçš„å˜åŒ–
"""

import os
import sys
import tempfile
import shutil
import subprocess
import argparse
import json
from pathlib import Path
from datetime import datetime
import numpy as np
import h5py

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.data_processing.encode import load_h5_events
from src.tools.event_video_generator import EventVideoGenerator


class RecursiveInferenceExperiment:
    """é€’å½’æ¨ç†å®éªŒç®¡ç†å™¨"""
    
    def __init__(self, iterations=10, debug=False):
        """
        Args:
            iterations: æ¯ä¸ªæ–‡ä»¶é€’å½’å¤„ç†æ¬¡æ•°
            debug: æ˜¯å¦å¯ç”¨debugæ¨¡å¼
        """
        self.iterations = iterations
        self.debug = debug
        
        # ç›®æ ‡æ–‡ä»¶è·¯å¾„ (åŸºäºCLAUDE.mdè®°å½•çš„è·¯å¾„)
        self.target_files = [
            "data_simu/physics_method/background_with_flare_events_test/composed_00504_bg_flare.h5",
            "DSEC_data/input/real_flare_zurich_city_03_a_t1288ms_20250908_173252.h5"
        ]
        
        # è¾“å‡ºç›®å½•ç»“æ„
        self.base_output_dir = Path("debug_output/repeat")
        self.base_output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¸´æ—¶ç›®å½•ç”¨äºinferenceè¾“å‡º
        self.temp_dir = Path("temp_recursive")
        
        # è§†é¢‘ç”Ÿæˆå™¨
        self.video_generator = EventVideoGenerator(sensor_size=(480, 640), frame_duration_ms=2.5, fps=30)
        
        # å®éªŒç»Ÿè®¡
        self.experiment_stats = {
            "start_time": datetime.now().isoformat(),
            "iterations": iterations,
            "target_files": self.target_files,
            "results": {}
        }
        
        print(f"ğŸ”„ é€’å½’æ¨ç†å®éªŒåˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“Š é€’å½’æ¬¡æ•°: {iterations}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.base_output_dir}")
        print(f"ğŸ¯ ç›®æ ‡æ–‡ä»¶: {len(self.target_files)}ä¸ª")
        
    def run_single_inference(self, input_file: str, output_file: str) -> bool:
        """
        è¿è¡Œå•æ¬¡inference
        
        Args:
            input_file: è¾“å…¥H5æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºH5æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # ä½¿ç”¨main.pyçš„inferenceæ¨¡å¼
            cmd = [
                sys.executable, "main.py", "inference",
                "--config", "configs/inference_config.yaml",
                "--input", input_file,
                "--output", output_file
            ]
            
            if self.debug:
                print(f"ğŸ”§ è¿è¡Œå‘½ä»¤: {' '.join(cmd)}")
            
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=PROJECT_ROOT)
            
            if result.returncode == 0:
                if self.debug:
                    print(f"âœ… InferenceæˆåŠŸ: {input_file} â†’ {output_file}")
                return True
            else:
                print(f"âŒ Inferenceå¤±è´¥: {result.stderr}")
                return False
                
        except Exception as e:
            print(f"âŒ Inferenceå¼‚å¸¸: {e}")
            return False
    
    def generate_video_from_h5(self, h5_file: str, video_file: str) -> bool:
        """
        ä»H5æ–‡ä»¶ç”ŸæˆMP4è§†é¢‘
        
        Args:
            h5_file: è¾“å…¥H5æ–‡ä»¶è·¯å¾„
            video_file: è¾“å‡ºMP4æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            if self.debug:
                print(f"ğŸ¬ ç”Ÿæˆè§†é¢‘: {h5_file} â†’ {video_file}")
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            Path(video_file).parent.mkdir(parents=True, exist_ok=True)
            
            # ä½¿ç”¨ç°æœ‰çš„è§†é¢‘ç”Ÿæˆå™¨
            self.video_generator.process_h5_file(h5_file, video_file)
            success = Path(video_file).exists()
            
            if success:
                if self.debug:
                    print(f"âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ: {video_file}")
                return True
            else:
                print(f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥: {video_file}")
                return False
                
        except Exception as e:
            print(f"âŒ è§†é¢‘ç”Ÿæˆå¼‚å¸¸: {e}")
            return False
    
    def analyze_recursive_progression(self, h5_files: list) -> dict:
        """
        åˆ†æé€’å½’å¤„ç†è¿‡ç¨‹ä¸­çš„æ•°æ®å˜åŒ–
        
        Args:
            h5_files: æŒ‰é€’å½’é¡ºåºæ’åˆ—çš„H5æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            
        Returns:
            dict: é€’å½’åˆ†æç»“æœ
        """
        try:
            stats = {
                "iteration_count": len(h5_files),
                "event_counts": [],
                "event_count_changes": [],
                "compression_ratios": [],
                "total_compression_ratio": 0.0
            }
            
            # åŠ è½½æ‰€æœ‰æ–‡ä»¶çš„äº‹ä»¶è®¡æ•°å¹¶è®¡ç®—å˜åŒ–
            previous_count = None
            for i, h5_file in enumerate(h5_files):
                if os.path.exists(h5_file):
                    events = load_h5_events(h5_file)
                    current_count = len(events)
                    stats["event_counts"].append(current_count)
                    
                    if previous_count is not None:
                        # è®¡ç®—ç›¸å¯¹äºä¸Šä¸€æ¬¡çš„å˜åŒ–
                        change_ratio = current_count / previous_count if previous_count > 0 else 0
                        stats["event_count_changes"].append(change_ratio)
                        stats["compression_ratios"].append(change_ratio)
                    
                    previous_count = current_count
            
            # è®¡ç®—æ€»ä½“å‹ç¼©æ¯”ç‡
            if len(stats["event_counts"]) >= 2:
                initial_count = stats["event_counts"][0]
                final_count = stats["event_counts"][-1]
                stats["total_compression_ratio"] = final_count / initial_count if initial_count > 0 else 0
                stats["initial_count"] = initial_count
                stats["final_count"] = final_count
                stats["total_change"] = final_count - initial_count
            
            return stats
            
        except Exception as e:
            print(f"âŒ é€’å½’åˆ†æå¼‚å¸¸: {e}")
            return {"error": str(e)}
    
    def process_single_file(self, target_file: str) -> bool:
        """
        å¤„ç†å•ä¸ªç›®æ ‡æ–‡ä»¶çš„é€’å½’inferenceå®éªŒ
        
        é€’å½’å¤„ç†æµç¨‹: 
        åŸå§‹æ–‡ä»¶ â†’ UNet â†’ ç»“æœ1 â†’ UNet â†’ ç»“æœ2 â†’ ... â†’ ç»“æœN
        
        Args:
            target_file: ç›®æ ‡H5æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸå®Œæˆæ‰€æœ‰é€’å½’æ­¥éª¤
        """
        file_name = Path(target_file).stem
        print(f"\nğŸ¯ å¼€å§‹é€’å½’å¤„ç†: {file_name}")
        
        # ä¸ºæ­¤æ–‡ä»¶åˆ›å»ºè¾“å‡ºç›®å½•
        file_output_dir = self.base_output_dir / file_name
        file_output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_file_dir = self.temp_dir / file_name
        temp_file_dir.mkdir(parents=True, exist_ok=True)
        
        successful_iterations = 0
        output_files = []
        current_input_file = target_file  # åˆå§‹è¾“å…¥æ˜¯åŸå§‹æ–‡ä»¶
        
        try:
            for i in range(self.iterations):
                print(f"  ğŸ”„ é€’å½’ {i+1}/{self.iterations}", end="")
                
                # å®šä¹‰å½“å‰é€’å½’æ­¥éª¤çš„è¾“å‡ºæ–‡ä»¶
                temp_h5_file = temp_file_dir / f"iteration_{i+1:02d}.h5"
                
                # è¿è¡Œinference: å½“å‰è¾“å…¥ â†’ UNet â†’ å½“å‰è¾“å‡º
                success = self.run_single_inference(current_input_file, str(temp_h5_file))
                
                if success and temp_h5_file.exists():
                    # ç§»åŠ¨åˆ°æœ€ç»ˆè¾“å‡ºç›®å½•
                    final_h5_file = file_output_dir / f"iteration_{i+1:02d}.h5"
                    shutil.move(str(temp_h5_file), str(final_h5_file))
                    output_files.append(str(final_h5_file))
                    
                    # ç”Ÿæˆè§†é¢‘
                    video_file = file_output_dir / f"iteration_{i+1:02d}.mp4"
                    video_success = self.generate_video_from_h5(str(final_h5_file), str(video_file))
                    
                    if video_success:
                        successful_iterations += 1
                        print(f" âœ…")
                        
                        # ğŸ”„ å…³é”®: å°†å½“å‰è¾“å‡ºè®¾ä¸ºä¸‹æ¬¡è¾“å…¥ï¼Œå½¢æˆé€’å½’é“¾
                        current_input_file = str(final_h5_file)
                        
                    else:
                        print(f" âš ï¸ (H5æˆåŠŸ,è§†é¢‘å¤±è´¥)")
                        # å³ä½¿è§†é¢‘å¤±è´¥ï¼Œä¹Ÿç»§ç»­é€’å½’é“¾
                        current_input_file = str(final_h5_file)
                        successful_iterations += 1
                else:
                    print(f" âŒ (åœæ­¢é€’å½’)")
                    break  # å¦‚æœinferenceå¤±è´¥ï¼Œåœæ­¢é€’å½’é“¾
            
            # æ·»åŠ åŸå§‹æ–‡ä»¶åˆ°åˆ†æåºåˆ—çš„å¼€å¤´
            all_files_for_analysis = [target_file] + output_files
            
            # åˆ†æé€’å½’è¿‡ç¨‹
            recursive_stats = self.analyze_recursive_progression(all_files_for_analysis)
            
            # ä¿å­˜ç»Ÿè®¡ç»“æœ
            stats_file = file_output_dir / "recursive_experiment_stats.json"
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "file_name": file_name,
                    "target_file": target_file,
                    "successful_iterations": successful_iterations,
                    "total_iterations": self.iterations,
                    "success_rate": successful_iterations / self.iterations,
                    "recursive_analysis": recursive_stats
                }, f, indent=2, ensure_ascii=False)
            
            # ä¿å­˜åˆ°å…¨å±€ç»Ÿè®¡
            self.experiment_stats["results"][file_name] = {
                "successful_iterations": successful_iterations,
                "total_iterations": self.iterations,
                "success_rate": successful_iterations / self.iterations,
                "recursive_analysis": recursive_stats
            }
            
            print(f"  ğŸ“‹ å®Œæˆé€’å½’: {successful_iterations}/{self.iterations} æˆåŠŸ")
            
            # æ˜¾ç¤ºé€’å½’æ•ˆæœæ‘˜è¦
            if recursive_stats.get("initial_count") and recursive_stats.get("final_count"):
                initial = recursive_stats["initial_count"]
                final = recursive_stats["final_count"]
                ratio = recursive_stats["total_compression_ratio"]
                change = recursive_stats["total_change"]
                print(f"  ğŸ“Š äº‹ä»¶å˜åŒ–: {initial:,} â†’ {final:,} (æ¯”ç‡: {ratio:.3f}, å˜åŒ–: {change:+,})")
            
            return successful_iterations > 0
            
        except Exception as e:
            print(f"âŒ é€’å½’å¤„ç†å¤±è´¥ {target_file}: {e}")
            return False
            
        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            if temp_file_dir.exists():
                shutil.rmtree(temp_file_dir)
    
    def run_experiment(self) -> bool:
        """è¿è¡Œå®Œæ•´é€’å½’å®éªŒ"""
        print(f"\nğŸš€ å¼€å§‹é€’å½’æ¨ç†å®éªŒ")
        print(f"{'='*50}")
        
        overall_success = True
        
        try:
            # ç¡®ä¿ä¸´æ—¶ç›®å½•å­˜åœ¨
            self.temp_dir.mkdir(parents=True, exist_ok=True)
            
            # å¤„ç†æ¯ä¸ªç›®æ ‡æ–‡ä»¶
            for target_file in self.target_files:
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if not Path(target_file).exists():
                    print(f"âŒ ç›®æ ‡æ–‡ä»¶ä¸å­˜åœ¨: {target_file}")
                    overall_success = False
                    continue
                
                file_success = self.process_single_file(target_file)
                if not file_success:
                    overall_success = False
            
            # ä¿å­˜å…¨å±€ç»Ÿè®¡æŠ¥å‘Š
            self.experiment_stats["end_time"] = datetime.now().isoformat()
            self.experiment_stats["overall_success"] = overall_success
            
            global_stats_file = self.base_output_dir / "global_recursive_stats.json"
            with open(global_stats_file, 'w', encoding='utf-8') as f:
                json.dump(self.experiment_stats, f, indent=2, ensure_ascii=False)
            
            # æ‰“å°æ€»ç»“
            print(f"\nğŸ“Š é€’å½’å®éªŒæ€»ç»“")
            print(f"{'='*50}")
            print(f"æ€»ä½“æˆåŠŸ: {'âœ…' if overall_success else 'âŒ'}")
            print(f"å¤„ç†æ–‡ä»¶: {len(self.target_files)}ä¸ª")
            print(f"é€’å½’æ¬¡æ•°: {self.iterations}")
            print(f"è¾“å‡ºç›®å½•: {self.base_output_dir}")
            print(f"å…¨å±€ç»Ÿè®¡: {global_stats_file}")
            
            for file_name, result in self.experiment_stats["results"].items():
                success_rate = result["success_rate"]
                recursive_analysis = result["recursive_analysis"]
                print(f"  ğŸ“ {file_name}: {success_rate*100:.1f}% æˆåŠŸ")
                
                if "total_compression_ratio" in recursive_analysis:
                    ratio = recursive_analysis["total_compression_ratio"]
                    initial = recursive_analysis.get("initial_count", 0)
                    final = recursive_analysis.get("final_count", 0)
                    print(f"    ğŸ”„ é€’å½’æ•ˆæœ: {initial:,} â†’ {final:,} (æ¯”ç‡: {ratio:.3f})")
            
            return overall_success
            
        except Exception as e:
            print(f"âŒ å®éªŒå¼‚å¸¸: {e}")
            return False
            
        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            if self.temp_dir.exists():
                shutil.rmtree(self.temp_dir)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="é€’å½’æ¨ç†å®éªŒå·¥å…·")
    parser.add_argument("--iterations", type=int, default=10, help="æ¯ä¸ªæ–‡ä»¶çš„é€’å½’æ¬¡æ•° (é»˜è®¤: 10)")
    parser.add_argument("--debug", action="store_true", help="å¯ç”¨debugæ¨¡å¼")
    
    args = parser.parse_args()
    
    # åˆ›å»ºå®éªŒç®¡ç†å™¨
    experiment = RecursiveInferenceExperiment(
        iterations=args.iterations,
        debug=args.debug
    )
    
    # è¿è¡Œå®éªŒ
    success = experiment.run_experiment()
    
    if success:
        print(f"\nğŸ‰ é€’å½’å®éªŒå®ŒæˆæˆåŠŸ!")
        return 0
    else:
        print(f"\nğŸ’¥ é€’å½’å®éªŒéƒ¨åˆ†å¤±è´¥!")
        return 1


if __name__ == '__main__':
    import sys
    sys.exit(main())