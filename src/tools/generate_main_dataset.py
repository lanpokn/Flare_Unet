#!/usr/bin/env python3
"""
ä¸»å®éªŒæ•°æ®é›†ç”Ÿæˆå™¨ - ç»Ÿä¸€å¤„ç†ä»¿çœŸå’ŒçœŸå®æ•°æ®é›†

åŸºäºLinuså“²å­¦ï¼š
- æ•°æ®ç»“æ„æ­£ç¡®: æ‰«æå›ºå®š100ms H5æ–‡ä»¶ â†’ å¤šæ–¹æ³•å¤„ç† â†’ ç»Ÿä¸€å¯è§†åŒ–
- æ¶ˆé™¤ç‰¹æ®Šæƒ…å†µ: ç»Ÿä¸€ä»¿çœŸ/çœŸå®æ•°æ®å¤„ç†æµç¨‹ï¼Œåªéœ€åˆ‡æ¢è¾“å…¥ç›®å½•
- å®ç”¨ä¸»ä¹‰: è§£å†³è®ºæ–‡ä¸»å®éªŒæ•°æ®é›†ç”Ÿæˆçš„å®é™…éœ€æ±‚

åŠŸèƒ½ï¼š
1. è¯»å–è¾“å…¥ç›®å½•ï¼ˆä»¿çœŸæˆ–çœŸå®æ•°æ®ï¼‰å’Œå¯¹åº”çš„targetç›®å½•
2. è¿è¡Œæ‰€æœ‰å¤„ç†æ–¹æ³•ï¼š
   - 5ä¸ªUNetæƒé‡å˜ä½“ (standard, full, simple, simple_timeRandom, physics_noRandom)
   - PFD-A (score_select=1)
   - PFD-B (score_select=0)
   - EFR (çº¿æ€§æ¢³çŠ¶æ»¤æ³¢å™¨)
   - Baseline (çº¯encode-decode)
3. ç”Ÿæˆæ‰€æœ‰æ–¹æ³•çš„å¯è§†åŒ–è§†é¢‘
4. è¾“å‡ºç›®å½•ç»“æ„ç»Ÿä¸€ï¼Œä¾¿äºåç»­åˆ†æ

è¾“å‡ºç›®å½•ç»“æ„:
{output_base}/
â”œâ”€â”€ input/              # åŸå§‹å«ç‚«å…‰æ•°æ®
â”œâ”€â”€ target/             # ç›®æ ‡å»ç‚«å…‰æ•°æ® (å¯é€‰)
â”œâ”€â”€ output/             # UNet3D standardæƒé‡
â”œâ”€â”€ output_full/        # UNet3D fullæƒé‡
â”œâ”€â”€ output_simple/      # UNet3D simpleæƒé‡
â”œâ”€â”€ output_simple_timeRandom/
â”œâ”€â”€ output_physics_noRandom/
â”œâ”€â”€ inputpfda/          # PFD-Aç»“æœ
â”œâ”€â”€ inputpfdb/          # PFD-Bç»“æœ
â”œâ”€â”€ inputefr/           # EFRç»“æœ
â”œâ”€â”€ outputbaseline/     # Baselineç»“æœ
â””â”€â”€ visualize/          # æ‰€æœ‰æ–¹æ³•çš„å¯è§†åŒ–è§†é¢‘
    â””â”€â”€ {filename}/
        â”œâ”€â”€ input.mp4
        â”œâ”€â”€ target.mp4 (å¦‚æœæœ‰target)
        â”œâ”€â”€ unet_standard.mp4
        â”œâ”€â”€ unet_full.mp4
        â”œâ”€â”€ unet_simple.mp4
        â”œâ”€â”€ unet_simple_timeRandom.mp4
        â”œâ”€â”€ unet_physics_noRandom.mp4
        â”œâ”€â”€ pfda_output.mp4
        â”œâ”€â”€ pfdb_output.mp4
        â”œâ”€â”€ efr_output.mp4
        â””â”€â”€ baseline_output.mp4

Usage:
    # ä»¿çœŸæ•°æ®é›†ï¼ˆé»˜è®¤ï¼‰
    python src/tools/generate_main_dataset.py

    # çœŸå®æ•°æ®é›†ï¼ˆDSECï¼‰
    python src/tools/generate_main_dataset.py \
      --input_dir DSEC_data/input \
      --output_base DSEC_results

    # çœŸå®æ•°æ®é›†ï¼ˆEVK4ï¼‰
    python src/tools/generate_main_dataset.py \
      --input_dir EVK4/input \
      --target_dir EVK4/target \
      --output_base EVK4_results

    # æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰3ä¸ªæ–‡ä»¶
    python src/tools/generate_main_dataset.py --test --num_samples 3
"""

import os
import sys
import shutil
import argparse
from pathlib import Path
from datetime import datetime
from typing import List, Dict
import subprocess

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.tools.event_video_generator import EventVideoGenerator
from src.data_processing.encode import load_h5_events, events_to_voxel
from src.data_processing.decode import voxel_to_events

# å¯¼å…¥å¤„ç†å™¨ç±»
sys.path.append(str(PROJECT_ROOT / 'ext' / 'PFD'))
sys.path.append(str(PROJECT_ROOT / 'ext' / 'EFR-main'))
from batch_pfd_processor import BatchPFDProcessor
from batch_efr_processor import BatchEFRProcessor


class MainDatasetGenerator:
    """ä¸»å®éªŒæ•°æ®é›†ç”Ÿæˆå™¨ - ç»Ÿä¸€å¤„ç†ä»¿çœŸå’ŒçœŸå®æ•°æ®"""

    def __init__(self,
                 input_dir: str = None,
                 target_dir: str = None,
                 output_base: str = "Main_data",
                 test_mode: bool = False):
        """
        Args:
            input_dir: è¾“å…¥ç›®å½• (å«ç‚«å…‰ï¼Œé»˜è®¤data_simu/physics_method/background_with_flare_events_test)
            target_dir: ç›®æ ‡ç›®å½• (å»ç‚«å…‰ï¼Œå¯é€‰ï¼Œé»˜è®¤data_simu/physics_method/background_with_light_events_test)
            output_base: è¾“å‡ºåŸºç¡€ç›®å½• (é»˜è®¤Main_dataï¼Œä»¿çœŸç”¨MainSimu_dataï¼ŒçœŸå®ç”¨MainReal_data)
            test_mode: æµ‹è¯•æ¨¡å¼ï¼ˆè·³è¿‡æŸäº›è€—æ—¶æ“ä½œï¼‰
        """
        # é»˜è®¤ä½¿ç”¨ä»¿çœŸæ•°æ®é›†è·¯å¾„
        if input_dir is None:
            self.input_source_dir = PROJECT_ROOT / "data_simu/physics_method/background_with_flare_events_test"
            # ä»¿çœŸæ•°æ®é»˜è®¤è¾“å‡ºç›®å½•
            if output_base == "Main_data":
                output_base = "MainSimu_data"
        else:
            self.input_source_dir = Path(input_dir)

        # Targetç›®å½•å¯é€‰ï¼ˆçœŸå®æ•°æ®å¯èƒ½æ²¡æœ‰ground truthï¼‰
        if target_dir is None and input_dir is None:
            # ä»…å½“ä½¿ç”¨é»˜è®¤ä»¿çœŸæ•°æ®æ—¶ï¼Œè‡ªåŠ¨è®¾ç½®target
            self.target_source_dir = PROJECT_ROOT / "data_simu/physics_method/background_with_light_events_test"
        elif target_dir is not None:
            self.target_source_dir = Path(target_dir)
        else:
            self.target_source_dir = None

        self.output_base = Path(output_base)
        self.test_mode = test_mode

        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„ï¼ˆåªä¿ç•™éœ€è¦çš„æ–¹æ³•ï¼‰
        self.input_dir = self.output_base / "input"
        self.target_dir = self.output_base / "target"
        self.inputpfda_dir = self.output_base / "inputpfda"
        self.inputpfdb_dir = self.output_base / "inputpfdb"
        self.output_full_dir = self.output_base / "output_full"
        self.output_simple_dir = self.output_base / "output_simple"
        self.outputbaseline_dir = self.output_base / "outputbaseline"
        self.inputefr_dir = self.output_base / "inputefr"
        self.visualize_dir = self.output_base / "visualize"

        # UNet checkpointé…ç½®
        checkpoint_base = PROJECT_ROOT / "checkpoints"
        self.unet_checkpoints = {
            'simple': str(checkpoint_base / 'event_voxel_deflare_simple' / 'checkpoint_epoch_0031_iter_040000.pth'),
            'full': str(checkpoint_base / 'event_voxel_deflare_full' / 'checkpoint_epoch_0031_iter_040000.pth'),
        }

        # åˆ›å»ºæ‰€æœ‰å¿…è¦çš„ç›®å½•
        for dir_path in [self.input_dir, self.target_dir, self.inputpfda_dir, self.inputpfdb_dir,
                         self.output_full_dir, self.output_simple_dir,
                         self.outputbaseline_dir, self.inputefr_dir, self.visualize_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)

        # è§†é¢‘ç”Ÿæˆå™¨
        self.video_generator = EventVideoGenerator(
            sensor_size=(480, 640),
            frame_duration_ms=2.5,
            fps=10
        )

        # åˆå§‹åŒ–å¤„ç†å™¨
        self.pfd_processor_a = BatchPFDProcessor(debug=False)
        self.pfd_processor_a.pfds_params['score_select'] = 1  # PFD-A

        self.pfd_processor_b = BatchPFDProcessor(debug=False)
        self.pfd_processor_b.pfds_params['score_select'] = 0  # PFD-B

        self.efr_processor = BatchEFRProcessor(debug=False)

        print(f"ğŸš€ ä¸»å®éªŒæ•°æ®é›†ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“‚ è¾“å…¥æº: {self.input_source_dir}")
        if self.target_source_dir:
            print(f"ğŸ“‚ ç›®æ ‡æº: {self.target_source_dir}")
        else:
            print(f"ğŸ“‚ ç›®æ ‡æº: æ—  (ä»…å¤„ç†input)")
        print(f"ğŸ“‚ è¾“å‡ºåŸºç¡€ç›®å½•: {self.output_base}")
        if test_mode:
            print(f"ğŸ§ª æµ‹è¯•æ¨¡å¼: å·²å¯ç”¨")

    def copy_input_target_files(self, num_samples: int = None) -> List[Path]:
        """
        å¤åˆ¶inputå’Œtargetæ–‡ä»¶åˆ°è¾“å‡ºç›®å½•

        Args:
            num_samples: é™åˆ¶å¤„ç†çš„æ–‡ä»¶æ•°é‡ï¼ˆæµ‹è¯•ç”¨ï¼‰

        Returns:
            å¤åˆ¶åçš„inputæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        print(f"\nğŸ“‹ Step 1: å¤åˆ¶è¾“å…¥å’Œç›®æ ‡æ–‡ä»¶")
        print("=" * 80)

        # è·å–æ‰€æœ‰H5æ–‡ä»¶
        input_files = sorted(list(self.input_source_dir.glob("*.h5")))

        if not input_files:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°è¾“å…¥æ–‡ä»¶: {self.input_source_dir}")

        # Targetæ–‡ä»¶å¯é€‰
        target_files = []
        if self.target_source_dir and self.target_source_dir.exists():
            target_files = sorted(list(self.target_source_dir.glob("*.h5")))
            if not target_files:
                print(f"âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°ç›®æ ‡æ–‡ä»¶: {self.target_source_dir}")
        else:
            print(f"âš ï¸  æ— targetç›®å½•ï¼Œä»…å¤„ç†input")

        # é™åˆ¶æ ·æœ¬æ•°é‡
        if num_samples:
            input_files = input_files[:num_samples]
            print(f"ğŸ§ª æµ‹è¯•æ¨¡å¼: åªå¤„ç†å‰ {num_samples} ä¸ªæ–‡ä»¶")

        print(f"ğŸ“„ æ‰¾åˆ° {len(input_files)} ä¸ªè¾“å…¥æ–‡ä»¶")

        # å¤åˆ¶inputæ–‡ä»¶
        copied_input_files = []
        for input_file in input_files:
            dest_file = self.input_dir / input_file.name
            if not dest_file.exists():
                shutil.copy2(input_file, dest_file)
                print(f"  âœ… å¤åˆ¶input: {input_file.name}")
            else:
                print(f"  â­ï¸  è·³è¿‡input: {input_file.name} (å·²å­˜åœ¨)")
            copied_input_files.append(dest_file)

        # å¤åˆ¶targetæ–‡ä»¶ï¼ˆåŒ¹é…çš„ï¼‰
        target_copied = 0
        if target_files:
            for input_file in input_files:
                # æŸ¥æ‰¾åŒ¹é…çš„targetæ–‡ä»¶ï¼ˆbg_flare â†’ bg_lightï¼‰
                matching_target = None
                expected_target_name = input_file.name.replace('_bg_flare.h5', '_bg_light.h5')
                for target_file in target_files:
                    if target_file.name == expected_target_name:
                        matching_target = target_file
                        break

                if matching_target:
                    dest_file = self.target_dir / matching_target.name
                    if not dest_file.exists():
                        shutil.copy2(matching_target, dest_file)
                        print(f"  âœ… å¤åˆ¶target: {matching_target.name}")
                    else:
                        print(f"  â­ï¸  è·³è¿‡target: {matching_target.name} (å·²å­˜åœ¨)")
                    target_copied += 1
                else:
                    print(f"  âš ï¸  æœªæ‰¾åˆ°åŒ¹é…çš„target: {input_file.name}")

        print(f"\nğŸ“Š å¤åˆ¶å®Œæˆ: {len(copied_input_files)} input, {target_copied} target")
        return copied_input_files

    def save_h5_events(self, events, output_path: Path):
        """ä¿å­˜äº‹ä»¶åˆ°H5æ–‡ä»¶ï¼ˆæ ‡å‡†æ ¼å¼ï¼‰"""
        import h5py
        import numpy as np

        with h5py.File(output_path, 'w') as f:
            events_group = f.create_group('events')
            events_group.create_dataset('t', data=events[:, 0].astype(np.int64),
                                       compression='gzip', compression_opts=9)
            events_group.create_dataset('x', data=events[:, 1].astype(np.uint16),
                                       compression='gzip', compression_opts=9)
            events_group.create_dataset('y', data=events[:, 2].astype(np.uint16),
                                       compression='gzip', compression_opts=9)
            events_group.create_dataset('p', data=events[:, 3].astype(np.int8),
                                       compression='gzip', compression_opts=9)

    def run_unet_inference(self, input_h5: Path, output_h5: Path, checkpoint_path: str, variant_name: str = "standard"):
        """è¿è¡ŒUNet3Dæ¨ç†ï¼ˆå¤ç”¨generate_dsec_dataset.pyçš„å®ç°ï¼‰"""
        import yaml
        config_path = PROJECT_ROOT / "configs" / "inference_config.yaml"

        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)

        config['model']['path'] = checkpoint_path

        # å†™å…¥ä¸´æ—¶é…ç½®
        temp_config_path = PROJECT_ROOT / f"configs/temp_inference_{variant_name}.yaml"
        with open(temp_config_path, 'w') as f:
            yaml.dump(config, f)

        cmd = [
            sys.executable, "main.py", "inference",
            "--config", str(temp_config_path),
            "--input", str(input_h5),
            "--output", str(output_h5)
        ]

        print(f"    ğŸ”§ Running UNet3D ({variant_name})...")
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=PROJECT_ROOT, timeout=300)

            if result.returncode == 0:
                print(f"    âœ… UNet3D ({variant_name}) completed")
                success = True
            else:
                print(f"    âŒ UNet3D ({variant_name}) failed")
                success = False
        except subprocess.TimeoutExpired:
            print(f"    âŒ UNet3D ({variant_name}) timeout")
            success = False
        except Exception as e:
            print(f"    âŒ UNet3D ({variant_name}) exception: {e}")
            success = False
        finally:
            if temp_config_path.exists():
                temp_config_path.unlink()

        return success

    def run_all_unet_variants(self, input_h5: Path, filename: str) -> dict:
        """è¿è¡Œæ‰€æœ‰UNetæƒé‡å˜ä½“ï¼ˆåªè¿è¡Œsimpleå’Œfullï¼‰"""
        outputs = {}
        variants = [
            ('full', self.output_full_dir),
            ('simple', self.output_simple_dir),
        ]

        for variant_name, output_dir in variants:
            output_h5 = output_dir / filename
            checkpoint_path = self.unet_checkpoints[variant_name]

            if not Path(checkpoint_path).exists():
                print(f"    âš ï¸  UNet3D ({variant_name}) skipped - checkpoint not found")
                continue

            success = self.run_unet_inference(input_h5, output_h5, checkpoint_path, variant_name)

            if success and output_h5.exists():
                outputs[variant_name] = output_h5

        print(f"    ğŸ“Š UNet variants completed: {len(outputs)}/2")
        return outputs

    def run_baseline_processing(self, input_h5: Path, output_h5: Path):
        """è¿è¡ŒBaselineï¼ˆç¼–è§£ç onlyï¼‰å¤„ç†"""
        print(f"  ğŸ”§ Running Baseline processing...")
        try:
            events_np = load_h5_events(str(input_h5))
            voxel = events_to_voxel(events_np, num_bins=8, sensor_size=(480, 640), fixed_duration_us=100000)
            output_events = voxel_to_events(voxel, total_duration=100000, sensor_size=(480, 640))
            self.save_h5_events(output_events, output_h5)
            print(f"  âœ… Baseline processing completed")
        except Exception as e:
            print(f"  âŒ Baseline processing failed: {e}")

    def process_single_file(self, input_h5: Path, filename: str) -> bool:
        """
        å¤„ç†å•ä¸ªH5æ–‡ä»¶ï¼ˆæ‰€æœ‰æ–¹æ³•ï¼‰

        Args:
            input_h5: è¾“å…¥H5æ–‡ä»¶è·¯å¾„
            filename: æ–‡ä»¶å

        Returns:
            æ˜¯å¦æˆåŠŸå¤„ç†
        """
        print(f"\nğŸ“ Processing: {filename}")
        print("-" * 80)

        try:
            # Step 1: UNet3D (simpleå’Œfull)
            print(f"  ğŸ§  Running UNet variants (simple, full)...")
            unet_outputs = self.run_all_unet_variants(input_h5, filename)

            # Step 2: PFD-A
            print(f"  ğŸ”§ Running PFD-A processing...")
            pfda_h5 = self.inputpfda_dir / filename
            self.pfd_processor_a.process_single_file(input_h5, pfda_h5, file_idx=0)

            # Step 3: PFD-B
            print(f"  ğŸ”§ Running PFD-B processing...")
            pfdb_h5 = self.inputpfdb_dir / filename
            self.pfd_processor_b.process_single_file(input_h5, pfdb_h5, file_idx=0)

            # Step 4: EFR
            print(f"  ğŸ”§ Running EFR processing...")
            efr_h5 = self.inputefr_dir / filename
            self.efr_processor.process_single_file(input_h5, efr_h5, file_idx=0)

            # Step 5: Baseline
            baseline_h5 = self.outputbaseline_dir / filename
            self.run_baseline_processing(input_h5, baseline_h5)

            # Step 6: ç”Ÿæˆå¯è§†åŒ–
            print(f"  ğŸ¬ Generating visualizations...")
            target_h5 = self.target_dir / filename
            self.generate_visualizations(
                filename, input_h5, target_h5, unet_outputs,
                pfda_h5, pfdb_h5, efr_h5, baseline_h5
            )

            print(f"  âœ… File completed: {filename}")
            return True

        except Exception as e:
            print(f"  âŒ File failed: {filename} - {e}")
            import traceback
            traceback.print_exc()
            return False

    def generate_visualizations(self, base_filename: str,
                               input_h5: Path,
                               target_h5: Path,
                               unet_outputs: dict,
                               pfda_h5: Path,
                               pfdb_h5: Path,
                               efr_h5: Path,
                               baseline_h5: Path):
        """ç”Ÿæˆæ‰€æœ‰æ–¹æ³•çš„å¯è§†åŒ–"""
        vis_subdir = self.visualize_dir / Path(base_filename).stem
        vis_subdir.mkdir(parents=True, exist_ok=True)

        print(f"    ğŸ¬ Generating visualizations to: {vis_subdir.name}/")

        # å®šä¹‰æ‰€æœ‰éœ€è¦å¯è§†åŒ–çš„æ–‡ä»¶
        vis_tasks = [
            (input_h5, "input"),
        ]

        # Targetå¯é€‰
        if target_h5.exists():
            vis_tasks.append((target_h5, "target"))

        # æ·»åŠ æ‰€æœ‰UNetå˜ä½“
        for variant, h5_path in unet_outputs.items():
            vis_tasks.append((h5_path, f"unet_{variant}"))

        # æ·»åŠ å…¶ä»–æ–¹æ³•
        vis_tasks.extend([
            (pfda_h5, "pfda_output"),
            (pfdb_h5, "pfdb_output"),
            (efr_h5, "efr_output"),
            (baseline_h5, "baseline_output")
        ])

        for h5_file, method_name in vis_tasks:
            if h5_file.exists():
                try:
                    output_video = vis_subdir / f"{method_name}.mp4"
                    self.video_generator.process_h5_file(str(h5_file), str(output_video))
                    print(f"      âœ… {method_name}.mp4")
                except Exception as e:
                    print(f"      âŒ {method_name} failed: {e}")

    def generate_all(self, num_samples: int = None):
        """
        ç”Ÿæˆå®Œæ•´çš„ä¸»å®éªŒæ•°æ®é›†

        Args:
            num_samples: é™åˆ¶å¤„ç†çš„æ–‡ä»¶æ•°é‡ï¼ˆæµ‹è¯•ç”¨ï¼‰
        """
        print(f"\nğŸš€ å¼€å§‹ç”Ÿæˆä¸»å®éªŒæ•°æ®é›†")
        print("=" * 80)
        print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 80)

        # Step 1: å¤åˆ¶inputå’Œtargetæ–‡ä»¶
        input_files = self.copy_input_target_files(num_samples)

        if not input_files:
            print("âŒ æ²¡æœ‰æ–‡ä»¶éœ€è¦å¤„ç†")
            return

        # Step 2: å¤„ç†æ¯ä¸ªæ–‡ä»¶
        print(f"\nğŸ”„ Step 2: å¤„ç†æ‰€æœ‰æ–‡ä»¶ï¼ˆ{len(input_files)} ä¸ªï¼‰")
        print("=" * 80)

        success_count = 0
        for idx, input_file in enumerate(input_files, 1):
            print(f"\n[{idx}/{len(input_files)}]")
            if self.process_single_file(input_file, input_file.name):
                success_count += 1

        # Final summary
        print("\n" + "=" * 80)
        print(f"ğŸ‰ ä¸»å®éªŒæ•°æ®é›†ç”Ÿæˆå®Œæˆ!")
        print(f"ğŸ“Š å¤„ç†ç»“æœ: {success_count}/{len(input_files)} æ–‡ä»¶æˆåŠŸ")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {self.output_base}")
        print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 80)

        # è¾“å‡ºç›®å½•ç»“æ„è¯´æ˜
        print(f"\nğŸ“ è¾“å‡ºç›®å½•ç»“æ„:")
        print(f"  â€¢ input/               å«ç‚«å…‰æ•°æ®")
        if self.target_source_dir:
            print(f"  â€¢ target/              ç›®æ ‡å»ç‚«å…‰æ•°æ®")
        print(f"  â€¢ output_full/         UNet3D fullæƒé‡ç»“æœ")
        print(f"  â€¢ output_simple/       UNet3D simpleæƒé‡ç»“æœ")
        print(f"  â€¢ inputpfda/           PFD-Aç»“æœ")
        print(f"  â€¢ inputpfdb/           PFD-Bç»“æœ")
        print(f"  â€¢ inputefr/            EFRç»“æœ")
        print(f"  â€¢ outputbaseline/      Baselineç»“æœ")
        print(f"  â€¢ visualize/           æ‰€æœ‰æ–¹æ³•çš„å¯è§†åŒ–è§†é¢‘")


def main():
    parser = argparse.ArgumentParser(
        description="ä¸»å®éªŒæ•°æ®é›†ç”Ÿæˆå™¨ - ç»Ÿä¸€å¤„ç†ä»¿çœŸå’ŒçœŸå®æ•°æ®é›†"
    )
    parser.add_argument("--input_dir", help="è¾“å…¥ç›®å½• (é»˜è®¤: data_simu/physics_method/background_with_flare_events_test)")
    parser.add_argument("--target_dir", help="ç›®æ ‡ç›®å½• (å¯é€‰ï¼Œé»˜è®¤ä»¿çœŸæ•°æ®ä½¿ç”¨background_with_light_events_test)")
    parser.add_argument("--output_base", default="Main_data", help="è¾“å‡ºåŸºç¡€ç›®å½• (é»˜è®¤Main_dataï¼Œä»¿çœŸè‡ªåŠ¨æ”¹ä¸ºMainSimu_data)")
    parser.add_argument("--test", action="store_true", help="æµ‹è¯•æ¨¡å¼")
    parser.add_argument("--num_samples", type=int, help="é™åˆ¶å¤„ç†çš„æ–‡ä»¶æ•°é‡ï¼ˆæµ‹è¯•ç”¨ï¼‰")

    args = parser.parse_args()

    generator = MainDatasetGenerator(
        input_dir=args.input_dir,
        target_dir=args.target_dir,
        output_base=args.output_base,
        test_mode=args.test
    )

    # ç”Ÿæˆå®Œæ•´æ•°æ®é›†
    generator.generate_all(num_samples=args.num_samples)


if __name__ == "__main__":
    main()
