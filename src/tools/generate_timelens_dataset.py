#!/usr/bin/env python3
"""
TimeLensæ•°æ®é›†ç”Ÿæˆå·¥å…· - ä»DSECæ•°æ®æå–2ç§’ç‰‡æ®µå¹¶åº”ç”¨å„ç§äº‹ä»¶å¤„ç†æ–¹æ³•

åŠŸèƒ½:
1. ä»DSECè®­ç»ƒæ•°æ®ä¸­æå–å‰2ç§’ç‰‡æ®µï¼ˆevents + images + timestampsï¼‰
2. åˆ›å»ºoriginalåŸºå‡†æ•°æ®é›†
3. åº”ç”¨å„ç§äº‹ä»¶å¤„ç†æ–¹æ³•ï¼ˆUNetå˜ä½“ + PFD-A/B + EFR + Baselineï¼‰
4. ç”ŸæˆTimeLensæ ¼å¼çš„å®Œæ•´æ•°æ®é›†

è¾“å‡ºç»“æ„:
timelens/
â”œâ”€â”€ zurich_city_03_a_0-2s_original/          # åŸå§‹æ•°æ®
â”œâ”€â”€ zurich_city_03_a_0-2s_unet_simple/       # UNet simpleæƒé‡
â”œâ”€â”€ zurich_city_03_a_0-2s_unet_full/         # UNet fullæƒé‡
â”œâ”€â”€ zurich_city_03_a_0-2s_pfda/              # PFD-Aå¤„ç†
â”œâ”€â”€ zurich_city_03_a_0-2s_pfdb/              # PFD-Bå¤„ç†
â”œâ”€â”€ zurich_city_03_a_0-2s_efr/               # EFRå¤„ç†
â””â”€â”€ zurich_city_03_a_0-2s_baseline/          # Baselineç¼–è§£ç 
"""

import sys
from pathlib import Path
import argparse
import shutil
import numpy as np
import h5py
import hdf5plugin  # å…³é”®ï¼šå¤„ç†DSECå‹ç¼©HDF5
from tqdm import tqdm
from typing import Dict, List, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent.parent))

from src.data_processing.encode import load_h5_events, events_to_voxel
from src.data_processing.decode import voxel_to_events
from src.training.training_factory import TrainingFactory
from src.utils.config_loader import load_test_config
import torch


class TimeLensDatasetGenerator:
    """TimeLensæ•°æ®é›†ç”Ÿæˆå™¨"""

    def __init__(self,
                 dsec_source_dir: str,
                 output_base_dir: str = "timelens",
                 duration_seconds: float = 2.0,  # â­é»˜è®¤2ç§’ï¼ˆDSEC RGBç›¸æœº20FPSï¼Œçº¦40å¸§ï¼‰
                 image_subsample: int = 1,  # å›¾åƒé™é‡‡æ ·ï¼š1=ä¸é™é‡‡æ ·ï¼ˆDSEC RGBå·²ç»æ˜¯20FPSï¼‰
                 debug: bool = False):
        """
        Args:
            dsec_source_dir: DSECæºç›®å½•è·¯å¾„ï¼ˆå¦‚zurich_city_03_aï¼‰
            output_base_dir: è¾“å‡ºåŸºç¡€ç›®å½•
            duration_seconds: æå–æ—¶é•¿ï¼ˆç§’ï¼‰
            image_subsample: å›¾åƒé™é‡‡æ ·å› å­ï¼ˆé€šå¸¸ä¿æŒ1ï¼ŒDSEC RGBå·²ç»æ˜¯20FPSï¼‰
            debug: Debugæ¨¡å¼

        Note:
            DSEC timestampså•ä½æ˜¯å¾®ç§’(Î¼s)ï¼Œä¸æ˜¯çº³ç§’
            RGBç›¸æœºå¸§ç‡çº¦20FPSï¼Œevent cameraé«˜é€Ÿå¼‚æ­¥
        """
        self.dsec_source = Path(dsec_source_dir)
        self.output_base = Path(output_base_dir)
        self.duration_s = duration_seconds
        self.duration_us = int(duration_seconds * 1e6)  # â­ä¿®å¤ï¼šDSECæ—¶é—´æˆ³æ˜¯å¾®ç§’(Î¼s)ï¼Œä¸æ˜¯çº³ç§’
        self.image_subsample = image_subsample
        self.debug = debug

        # æå–åºåˆ—åç§°
        self.sequence_name = self.dsec_source.name

        # éªŒè¯æºç›®å½•ç»“æ„
        self._validate_source_structure()

        # UNetæƒé‡é…ç½®
        self.unet_checkpoints = {
            'simple': 'checkpoints/event_voxel_deflare_simple/checkpoint_epoch_0031_iter_040000.pth',
            'full': 'checkpoints/event_voxel_deflare_full/checkpoint_epoch_0031_iter_040000.pth',
            'physics_noRandom_noTen': 'checkpoints/event_voxel_deflare_physics_noRandom_noTen_method/checkpoint_epoch_0031_iter_040000.pth',
            'simple_old': 'checkpoints_old/event_voxel_deflare_simple/checkpoint_epoch_0027_iter_076250.pth',
        }

        print(f"âœ… TimeLensç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   æºåºåˆ—: {self.sequence_name}")
        print(f"   æå–æ—¶é•¿: {self.duration_s}ç§’")
        print(f"   è¾“å‡ºç›®å½•: {self.output_base}")

    def _validate_source_structure(self):
        """éªŒè¯DSECæºç›®å½•ç»“æ„"""
        required = {
            'events/left/events.h5': self.dsec_source / 'events/left/events.h5',
            'images/timestamps.txt': self.dsec_source / 'images/timestamps.txt',
            'images/left/distorted': self.dsec_source / 'images/left/distorted',
        }

        for name, path in required.items():
            if not path.exists():
                raise FileNotFoundError(f"âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶: {name}")

        print(f"âœ… DSECæºç›®å½•ç»“æ„éªŒè¯é€šè¿‡: {self.dsec_source}")

    def generate_all(self):
        """ç”Ÿæˆå®Œæ•´TimeLensæ•°æ®é›†ï¼ˆæ‰€æœ‰å˜ä½“ï¼‰"""
        print("\n" + "="*80)
        print("ğŸš€ å¼€å§‹ç”ŸæˆTimeLensæ•°æ®é›†")
        print("="*80)

        # Step 1: æå–å¹¶åˆ›å»ºoriginalæ•°æ®é›†
        print(f"\nã€Step 1/3ã€‘æå–å‰{self.duration_s}ç§’æ•°æ®ï¼Œåˆ›å»ºoriginalæ•°æ®é›†...")
        original_dir = self._create_original_dataset()

        # Step 2: åˆ›å»ºå¤„ç†å˜ä½“
        print("\nã€Step 2/3ã€‘åº”ç”¨å„ç§äº‹ä»¶å¤„ç†æ–¹æ³•...")
        self._create_processed_variants(original_dir)

        # Step 3: ç”Ÿæˆæ‘˜è¦
        print("\nã€Step 3/3ã€‘ç”Ÿæˆæ•°æ®é›†æ‘˜è¦...")
        self._generate_summary()

        print("\n" + "="*80)
        print("âœ… TimeLensæ•°æ®é›†ç”Ÿæˆå®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_base.absolute()}")
        print("="*80)

    def _create_original_dataset(self) -> Path:
        """åˆ›å»ºoriginalæ•°æ®é›†ï¼ˆå‰Nç§’æ•°æ®ï¼‰"""
        # è¾“å‡ºç›®å½•å: zurich_city_03_a_0-1s_original
        output_name = f"{self.sequence_name}_0-{int(self.duration_s)}s_original"
        output_dir = self.output_base / output_name

        # å¦‚æœå·²å­˜åœ¨ï¼Œè·³è¿‡
        if (output_dir / 'events/left/events.h5').exists():
            print(f"âœ… Originalæ•°æ®é›†å·²å­˜åœ¨ï¼Œè·³è¿‡: {output_name}")
            return output_dir

        # åˆ›å»ºTimeLensç›®å½•ç»“æ„
        events_dir = output_dir / 'events/left'
        images_dir = output_dir / 'images/left/distorted'
        events_dir.mkdir(parents=True, exist_ok=True)
        images_dir.mkdir(parents=True, exist_ok=True)

        print(f"ğŸ“ åˆ›å»ºç›®å½•: {output_dir}")

        # Step 1: å¤„ç†timestamps.txtï¼ˆç¡®å®šå›¾åƒæ—¶é—´èŒƒå›´ï¼‰
        print("   â”œâ”€ å¤„ç†timestamps.txt...")
        valid_image_indices, first_t_ns, last_t_ns = self._extract_timestamps(
            self.dsec_source / 'images/timestamps.txt',
            output_dir / 'images/timestamps.txt'
        )

        # Step 2: å¤åˆ¶å¯¹åº”çš„å›¾åƒ
        print(f"   â”œâ”€ å¤åˆ¶{len(valid_image_indices)}å¼ å›¾åƒ...")
        self._copy_images(valid_image_indices, images_dir)

        # Step 3: æå–eventsï¼ˆä½¿ç”¨å›¾åƒæ—¶é—´èŒƒå›´ï¼‰
        print("   â””â”€ æå–events.h5...")
        self._extract_events(
            self.dsec_source / 'events/left/events.h5',
            events_dir / 'events.h5',
            first_t_ns,
            last_t_ns
        )

        print(f"âœ… Originalæ•°æ®é›†åˆ›å»ºå®Œæˆ: {output_name}")
        return output_dir

    def _extract_timestamps(self, source_file: Path, output_file: Path) -> Tuple[List[int], int, int]:
        """
        æå–å‰Nç§’çš„æ—¶é—´æˆ³å¹¶é™é‡‡æ ·

        Returns:
            (valid_indices, first_t_ns, last_t_ns)
        """
        # è¯»å–æ‰€æœ‰æ—¶é—´æˆ³
        timestamps_ns = []
        with open(source_file, 'r') as f:
            for line in f:
                timestamps_ns.append(int(line.strip()))

        # æ‰¾åˆ°æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„æ—¶é—´æˆ³ï¼ˆDSECæ—¶é—´æˆ³å•ä½ï¼šå¾®ç§’ï¼‰
        first_t_us = timestamps_ns[0]
        cutoff_t_us = first_t_us + self.duration_us

        valid_indices = []
        valid_timestamps = []

        for idx, t in enumerate(timestamps_ns):
            if t <= cutoff_t_us:
                # â­ é™é‡‡æ ·ï¼šæ¯image_subsampleå¸§å–1å¸§
                if idx % self.image_subsample == 0:
                    valid_indices.append(idx)
                    valid_timestamps.append(t)
            else:
                break

        # ä¿å­˜ç­›é€‰åçš„æ—¶é—´æˆ³
        with open(output_file, 'w') as f:
            for t in valid_timestamps:
                f.write(f"{t}\n")

        duration_s = (valid_timestamps[-1] - first_t_us) / 1e6 if valid_timestamps else 0
        print(f"      æ—¶é—´èŒƒå›´: {first_t_us} - {valid_timestamps[-1] if valid_timestamps else first_t_us} Î¼s")
        print(f"      æŒç»­æ—¶é•¿: {duration_s:.3f}ç§’")
        print(f"      åŸå§‹å¸§æ•°: {len([i for i,t in enumerate(timestamps_ns) if t <= cutoff_t_us])}")
        print(f"      é™é‡‡æ ·å: {len(valid_indices)} å¸§ (æ¯{self.image_subsample}å¸§å–1å¸§)")

        return valid_indices, first_t_us, valid_timestamps[-1] if valid_timestamps else first_t_us

    def _copy_images(self, valid_indices: List[int], output_dir: Path):
        """å¤åˆ¶æœ‰æ•ˆæ—¶é—´èŒƒå›´å†…çš„å›¾åƒ"""
        source_dir = self.dsec_source / 'images/left/distorted'

        for new_idx, old_idx in enumerate(valid_indices):
            source_img = source_dir / f"{old_idx:06d}.png"
            target_img = output_dir / f"{new_idx:06d}.png"

            if source_img.exists():
                shutil.copy2(source_img, target_img)
            else:
                print(f"âš ï¸  å›¾åƒä¸å­˜åœ¨: {source_img}")

    def _extract_events(self, source_h5: Path, output_h5: Path,
                        start_t_us: int, end_t_us: int):
        """æå–æŒ‡å®šæ—¶é—´èŒƒå›´çš„events - ä¿®å¤æ—¶é—´å•ä½(Î¼s)"""
        with h5py.File(source_h5, 'r') as f_in:
            # è¯»å–t_offsetï¼ˆDSECå…³é”®å…ƒæ•°æ®ï¼Œå•ä½ï¼šå¾®ç§’ï¼‰
            t_offset = f_in['t_offset'][()] if 't_offset' in f_in else 0

            print(f"      t_offset: {t_offset} Î¼s")
            print(f"      ç›®æ ‡æ—¶é—´èŒƒå›´: {start_t_us} - {end_t_us} Î¼s ({(end_t_us-start_t_us)/1e6:.3f}ç§’)")

            # â­ å…³é”®ä¼˜åŒ–ï¼šä½¿ç”¨searchsortedå¿«é€Ÿå®šä½ç´¢å¼•
            t_dataset = f_in['events/t']
            total_events = t_dataset.shape[0]

            print(f"      DSECæ–‡ä»¶æ€»äº‹ä»¶æ•°: {total_events:,}")

            # â­ åˆ†å—è¯»å–æ—¶é—´æˆ³ï¼ˆé¿å…åŠ è½½1.1äº¿äº‹ä»¶çš„å®Œæ•´æ•°ç»„ï¼‰
            print(f"      åˆ†å—æ‰«ææ—¶é—´æˆ³æ•°ç»„...")
            CHUNK_SIZE = 10_000_000  # æ¯æ¬¡10Mäº‹ä»¶
            idx_start = None
            idx_end = None

            for chunk_idx in range(0, total_events, CHUNK_SIZE):
                chunk_end = min(chunk_idx + CHUNK_SIZE, total_events)
                t_chunk = t_dataset[chunk_idx:chunk_end]
                t_absolute = t_chunk.astype(np.int64) + t_offset

                # æ‰¾èµ·å§‹ç´¢å¼•
                if idx_start is None and np.any(t_absolute >= start_t_us):
                    idx_start = chunk_idx + np.searchsorted(t_absolute, start_t_us, side='left')

                # æ‰¾ç»“æŸç´¢å¼•
                if np.any(t_absolute <= end_t_us):
                    local_end = np.searchsorted(t_absolute, end_t_us, side='right')
                    idx_end = chunk_idx + local_end

                # å·²ç»è¶…å‡ºèŒƒå›´ï¼Œåœæ­¢æ‰«æ
                if idx_start is not None and np.all(t_absolute > end_t_us):
                    break

                if (chunk_idx // CHUNK_SIZE) % 5 == 0:
                    print(f"        æ‰«æè¿›åº¦: {chunk_idx/total_events*100:.1f}%")

            if idx_start is None or idx_end is None:
                raise ValueError(f"âŒ æ—¶é—´èŒƒå›´å†…æ— äº‹ä»¶: {start_t_us} - {end_t_us} Î¼s")

            num_events = idx_end - idx_start
            print(f"      æå–äº‹ä»¶ç´¢å¼•: {idx_start:,} - {idx_end:,} (å…±{num_events:,}ä¸ª)")

            # åªè¯»å–éœ€è¦çš„èŒƒå›´
            t = t_dataset[idx_start:idx_end]
            x = f_in['events/x'][idx_start:idx_end]
            y = f_in['events/y'][idx_start:idx_end]
            p = f_in['events/p'][idx_start:idx_end]

            # è½¬ä¸ºç›¸å¯¹æ—¶é—´ï¼ˆä»0å¼€å§‹ï¼‰
            t_relative = t - t[0]

            # åˆ›å»ºè¾“å‡ºH5æ–‡ä»¶ï¼ˆTimeLensæ ¼å¼ï¼‰
            with h5py.File(output_h5, 'w') as f_out:
                events_group = f_out.create_group('events')

                # ä¿å­˜äº‹ä»¶æ•°æ®ï¼ˆä¿æŒDSECåŸå§‹æ•°æ®ç±»å‹ï¼‰
                events_group.create_dataset('t', data=t_relative, compression='gzip', compression_opts=9)
                events_group.create_dataset('x', data=x, compression='gzip', compression_opts=9)
                events_group.create_dataset('y', data=y, compression='gzip', compression_opts=9)
                events_group.create_dataset('p', data=p, compression='gzip', compression_opts=9)

                # ä¿å­˜å…ƒæ•°æ®
                f_out.create_dataset('t_offset', data=t_offset)

                print(f"      äº‹ä»¶ç»Ÿè®¡:")
                print(f"        - æ€»æ•°: {len(t_relative):,}")
                print(f"        - æ—¶é—´èŒƒå›´: {t_relative[0]} - {t_relative[-1]} Î¼s")
                print(f"        - æŒç»­æ—¶é•¿: {t_relative[-1] / 1e6:.3f}ç§’")
                print(f"        - æ­£äº‹ä»¶: {np.sum(p == 1):,}")
                print(f"        - è´Ÿäº‹ä»¶: {np.sum(p == 0):,}")

    def _create_processed_variants(self, original_dir: Path):
        """åˆ›å»ºå„ç§å¤„ç†å˜ä½“"""
        original_events_h5 = original_dir / 'events/left/events.h5'

        # è·å–æ‰€æœ‰å¤„ç†æ–¹æ³•
        methods = []

        # UNetå˜ä½“
        for name in self.unet_checkpoints.keys():
            methods.append(('unet_' + name, self._process_unet, name))

        # ä¼ ç»Ÿæ–¹æ³•
        methods.extend([
            ('pfda', self._process_pfda, None),
            ('pfdb', self._process_pfdb, None),
            ('efr', self._process_efr, None),
            ('baseline', self._process_baseline, None),
        ])

        # å¤„ç†æ¯ç§æ–¹æ³•
        for method_name, process_func, param in tqdm(methods, desc="å¤„ç†æ–¹æ³•"):
            print(f"\n   å¤„ç†: {method_name}")
            variant_dir = self._create_variant_structure(original_dir, method_name)

            # å¤„ç†events
            output_events_h5 = variant_dir / 'events/left/events.h5'

            # å¦‚æœå·²å­˜åœ¨ï¼Œè·³è¿‡
            if output_events_h5.exists():
                print(f"   â­ï¸  {method_name} å·²å­˜åœ¨ï¼Œè·³è¿‡")
                continue

            process_func(original_events_h5, output_events_h5, param)

            print(f"   âœ… {method_name} å®Œæˆ")

    def _create_variant_structure(self, original_dir: Path, suffix: str) -> Path:
        """åˆ›å»ºå˜ä½“ç›®å½•ç»“æ„å¹¶å¤åˆ¶å›¾åƒ+æ—¶é—´æˆ³"""
        # ç”Ÿæˆå˜ä½“ç›®å½•å: zurich_city_03_a_0-2s_unet_simple
        variant_name = original_dir.name.replace('_original', f'_{suffix}')
        variant_dir = self.output_base / variant_name

        # åˆ›å»ºç›®å½•ç»“æ„
        events_dir = variant_dir / 'events/left'
        images_dir = variant_dir / 'images'
        events_dir.mkdir(parents=True, exist_ok=True)
        images_dir.mkdir(parents=True, exist_ok=True)

        # å¤åˆ¶å›¾åƒå’Œæ—¶é—´æˆ³ï¼ˆç¡¬é“¾æ¥é¿å…é‡å¤å­˜å‚¨ï¼‰
        shutil.copytree(
            original_dir / 'images/left',
            variant_dir / 'images/left',
            dirs_exist_ok=True
        )
        shutil.copy2(
            original_dir / 'images/timestamps.txt',
            variant_dir / 'images/timestamps.txt'
        )

        return variant_dir

    def _process_unet(self, input_h5: Path, output_h5: Path, checkpoint_name: str):
        """UNetå¤„ç† - å†…å­˜å®‰å…¨ç‰ˆæœ¬ï¼ˆåŸºäºinference_single.pyï¼‰"""
        checkpoint_path = self.unet_checkpoints[checkpoint_name]

        # åŠ è½½æ¨¡å‹
        config = load_test_config('configs/test_config.yaml')
        config['model']['path'] = checkpoint_path

        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        factory = TrainingFactory(config)
        model = factory.create_model().to(device)

        # åŠ è½½checkpoint
        checkpoint = torch.load(checkpoint_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()

        # åŠ è½½eventsï¼ˆè½¬æ¢ä¸ºé¡¹ç›®æ ‡å‡†æ ¼å¼ï¼‰
        events_np = self._load_dsec_events_as_standard(input_h5)

        # åˆ†æ®µå¤„ç†ï¼ˆ20ms per segmentï¼‰
        segment_duration_us = 20000
        duration_us = int(events_np[:, 0].max() - events_np[:, 0].min())  # â­DSEC eventså·²ç»æ˜¯Î¼s
        num_segments = max(1, duration_us // segment_duration_us)

        # â­ å†…å­˜å®‰å…¨ç­–ç•¥ï¼šåŸºäºæ®µæ•°å’Œæ€»äº‹ä»¶æ•°æ™ºèƒ½é€‰æ‹©
        MAX_MEMORY_SEGMENTS = 30  # æ®µæ•°é˜ˆå€¼
        MEMORY_SAFETY_MARGIN = 0.8  # å†…å­˜å®‰å…¨ç³»æ•°ï¼ˆ80%ï¼‰

        # ä¼°ç®—å†…å­˜éœ€æ±‚ï¼ˆæ¯ä¸ªsegmentå¹³å‡äº‹ä»¶æ•° Ã— æ®µæ•° Ã— æ¯äº‹ä»¶å†…å­˜ï¼‰
        avg_events_per_seg = len(events_np) / max(num_segments, 1)
        estimated_memory_mb = (avg_events_per_seg * num_segments * 32) / (1024**2)  # 32å­—èŠ‚/äº‹ä»¶(4Ã—float64)

        print(f"      æ–‡ä»¶æ—¶é•¿: {duration_us/1000:.1f}ms, æ®µæ•°: {num_segments}")
        print(f"      ä¼°ç®—å†…å­˜éœ€æ±‚: {estimated_memory_mb:.1f}MB")

        # æ™ºèƒ½é€‰æ‹©å¤„ç†æ¨¡å¼
        use_streaming = (num_segments > MAX_MEMORY_SEGMENTS) or (estimated_memory_mb > 500)

        if not use_streaming:
            # å°æ–‡ä»¶ï¼šå†…å­˜å¤„ç†ï¼ˆå¿«é€Ÿï¼‰
            print(f"      âœ… å†…å­˜å¤„ç†æ¨¡å¼ï¼ˆ{num_segments}æ®µï¼Œ{estimated_memory_mb:.0f}MBï¼‰")
            final_events = self._process_segments_in_memory(
                events_np, model, device, num_segments, segment_duration_us
            )
        else:
            # å¤§æ–‡ä»¶ï¼šæµå¼ç£ç›˜å¤„ç†ï¼ˆå®‰å…¨ï¼‰
            import tempfile
            print(f"      âš ï¸  æµå¼ç£ç›˜å¤„ç†ï¼ˆ{num_segments}æ®µï¼Œ{estimated_memory_mb:.0f}MB > 500MBæˆ–æ®µæ•° > {MAX_MEMORY_SEGMENTS}ï¼‰")
            temp_dir = Path(tempfile.mkdtemp(prefix='timelens_unet_'))
            try:
                final_events = self._process_segments_streaming(
                    events_np, model, device, num_segments, segment_duration_us, temp_dir
                )
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                import shutil
                if temp_dir.exists():
                    shutil.rmtree(temp_dir)

        # ä¿å­˜ä¸ºDSECæ ¼å¼
        self._save_dsec_format_events(final_events, output_h5, input_h5)

    def _process_segments_in_memory(self, events_np: np.ndarray, model, device,
                                    num_segments: int, segment_duration_us: int) -> np.ndarray:
        """å†…å­˜å¤„ç†æ¨¡å¼ï¼ˆæ®µæ•° <= 50ï¼‰"""
        all_processed = []

        for seg_idx in range(num_segments):
            start_us = seg_idx * segment_duration_us
            end_us = start_us + segment_duration_us

            # â­ DSEC eventsæ—¶é—´æˆ³æ˜¯Î¼sï¼Œæ— éœ€è½¬æ¢
            mask = (events_np[:, 0] >= start_us) & (events_np[:, 0] < end_us)
            seg_events = events_np[mask].copy()

            if len(seg_events) == 0:
                continue

            # Events â†’ Voxel â†’ UNet â†’ Events
            voxel = events_to_voxel(seg_events, num_bins=8, sensor_size=(480, 640),
                                   fixed_duration_us=segment_duration_us)

            with torch.no_grad():
                # â­ events_to_voxelå·²ç»è¿”å›torch.Tensor (T,H,W) â†’ (1,T,H,W) â†’ (1,1,T,H,W)
                voxel_tensor = voxel.unsqueeze(0).unsqueeze(0).to(device)  # Add batch & channel dims
                output_voxel_tensor = model(voxel_tensor).cpu()[0,0]  # Remove batch & channel, keep as Tensor

            # â­ voxel_to_eventsæœŸæœ›Tensorè¾“å…¥
            output_events = voxel_to_events(output_voxel_tensor,
                                           total_duration=segment_duration_us,
                                           sensor_size=(480, 640))
            output_events[:, 0] += start_us  # â­ è°ƒæ•´ä¸ºÎ¼s
            all_processed.append(output_events)

        return np.vstack(all_processed) if all_processed else np.zeros((0, 4))

    def _process_segments_streaming(self, events_np: np.ndarray, model, device,
                                    num_segments: int, segment_duration_us: int,
                                    temp_dir: Path) -> np.ndarray:
        """æµå¼ç£ç›˜å¤„ç†æ¨¡å¼ï¼ˆæ®µæ•° > 30ï¼‰- é¿å…å†…å­˜ç´¯ç§¯"""
        print(f"      âš ï¸  æ®µæ•°{num_segments} > 30ï¼Œå¯ç”¨æµå¼ç£ç›˜å¤„ç†")

        MERGE_BATCH_SIZE = 20  # æ¯20æ®µåˆå¹¶ä¸€æ¬¡

        # Step 1: é€æ®µå¤„ç†å¹¶ä¿å­˜åˆ°ç£ç›˜
        for seg_idx in range(num_segments):
            start_us = seg_idx * segment_duration_us
            end_us = start_us + segment_duration_us

            # â­ DSEC eventsæ—¶é—´æˆ³æ˜¯Î¼s
            mask = (events_np[:, 0] >= start_us) & (events_np[:, 0] < end_us)
            seg_events = events_np[mask].copy()

            if len(seg_events) == 0:
                continue

            # Events â†’ Voxel â†’ UNet â†’ Events
            voxel = events_to_voxel(seg_events, num_bins=8, sensor_size=(480, 640),
                                   fixed_duration_us=segment_duration_us)

            with torch.no_grad():
                # â­ events_to_voxelå·²ç»è¿”å›torch.Tensor (T,H,W) â†’ (1,T,H,W) â†’ (1,1,T,H,W)
                voxel_tensor = voxel.unsqueeze(0).unsqueeze(0).to(device)  # Add batch & channel dims
                output_voxel_tensor = model(voxel_tensor).cpu()[0,0]  # Remove batch & channel, keep as Tensor

                # â­ å…³é”®ï¼šç«‹å³æ¸…ç†GPUç¼“å­˜
                del voxel_tensor
                if device.type == 'cuda':
                    torch.cuda.empty_cache()

            # â­ voxel_to_eventsæœŸæœ›Tensorè¾“å…¥
            output_events = voxel_to_events(output_voxel_tensor,
                                           total_duration=segment_duration_us,
                                           sensor_size=(480, 640))
            output_events[:, 0] += start_us  # â­ Î¼s

            # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶ï¼ˆé¿å…å†…å­˜ç´¯ç§¯ï¼‰
            np.save(temp_dir / f'seg_{seg_idx:04d}.npy', output_events)

            # å®šæœŸæŠ¥å‘Šè¿›åº¦+GPUå†…å­˜
            if (seg_idx + 1) % 10 == 0 or (seg_idx + 1) == num_segments:
                gpu_info = ""
                if device.type == 'cuda':
                    mem_alloc = torch.cuda.memory_allocated(device) / 1024**2
                    gpu_info = f", GPU: {mem_alloc:.1f}MB"
                print(f"      å·²å¤„ç† {seg_idx + 1}/{num_segments} æ®µ{gpu_info}")

        # Step 2: åˆ†æ‰¹ä»ç£ç›˜åˆå¹¶ï¼ˆé¿å…ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ®µï¼‰
        print(f"      åˆå¹¶ {num_segments} ä¸ªä¸´æ—¶æ®µæ–‡ä»¶...")

        all_batches = []
        batch_events = []

        for seg_idx in range(num_segments):
            seg_file = temp_dir / f'seg_{seg_idx:04d}.npy'
            if not seg_file.exists():
                continue

            seg_data = np.load(seg_file)
            batch_events.append(seg_data)

            # æ¯MERGE_BATCH_SIZEæ®µåˆå¹¶ä¸€æ¬¡
            if len(batch_events) >= MERGE_BATCH_SIZE:
                merged_batch = np.vstack(batch_events)
                all_batches.append(merged_batch)
                batch_events = []  # æ¸…ç©ºï¼Œé‡Šæ”¾å†…å­˜

        # å¤„ç†å‰©ä½™çš„æ®µ
        if batch_events:
            merged_batch = np.vstack(batch_events)
            all_batches.append(merged_batch)

        # æœ€ç»ˆåˆå¹¶æ‰€æœ‰æ‰¹æ¬¡
        print(f"      æœ€ç»ˆåˆå¹¶ {len(all_batches)} ä¸ªæ‰¹æ¬¡...")
        final_events = np.vstack(all_batches) if all_batches else np.zeros((0, 4))

        return final_events

    def _process_pfda(self, input_h5: Path, output_h5: Path, _):
        """PFD-Aå¤„ç†"""
        import sys
        pfd_path = Path(__file__).parent.parent.parent / 'ext/PFD'
        sys.path.insert(0, str(pfd_path))
        from batch_pfd_processor import BatchPFDProcessor

        processor = BatchPFDProcessor(debug=False)
        processor.pfds_params['score_select'] = 1  # PFD-A

        # è½¬æ¢ä¸ºä¸´æ—¶æ ‡å‡†æ ¼å¼å¤„ç†
        temp_h5 = input_h5.parent / 'temp_pfda.h5'
        self._convert_dsec_to_standard(input_h5, temp_h5)

        processor.process_single_file(temp_h5, temp_h5.parent / 'temp_pfda_out.h5', file_idx=0)

        # è½¬æ¢å›DSECæ ¼å¼
        self._convert_standard_to_dsec(temp_h5.parent / 'temp_pfda_out.h5', output_h5, input_h5)

        # æ¸…ç†
        temp_h5.unlink()
        (temp_h5.parent / 'temp_pfda_out.h5').unlink()

    def _process_pfdb(self, input_h5: Path, output_h5: Path, _):
        """PFD-Bå¤„ç†"""
        import sys
        pfd_path = Path(__file__).parent.parent.parent / 'ext/PFD'
        sys.path.insert(0, str(pfd_path))
        from batch_pfd_processor import BatchPFDProcessor

        processor = BatchPFDProcessor(debug=False)
        processor.pfds_params['score_select'] = 0  # PFD-B

        temp_h5 = input_h5.parent / 'temp_pfdb.h5'
        self._convert_dsec_to_standard(input_h5, temp_h5)

        processor.process_single_file(temp_h5, temp_h5.parent / 'temp_pfdb_out.h5', file_idx=0)

        self._convert_standard_to_dsec(temp_h5.parent / 'temp_pfdb_out.h5', output_h5, input_h5)

        temp_h5.unlink()
        (temp_h5.parent / 'temp_pfdb_out.h5').unlink()

    def _process_efr(self, input_h5: Path, output_h5: Path, _):
        """EFRå¤„ç†"""
        import sys
        efr_path = Path(__file__).parent.parent.parent / 'ext/EFR-main'
        sys.path.insert(0, str(efr_path))
        from batch_efr_processor import BatchEFRProcessor

        processor = BatchEFRProcessor(debug=False)

        temp_h5 = input_h5.parent / 'temp_efr.h5'
        self._convert_dsec_to_standard(input_h5, temp_h5)

        processor.process_single_file(temp_h5, temp_h5.parent / 'temp_efr_out.h5', file_idx=0)

        self._convert_standard_to_dsec(temp_h5.parent / 'temp_efr_out.h5', output_h5, input_h5)

        temp_h5.unlink()
        (temp_h5.parent / 'temp_efr_out.h5').unlink()

    def _process_baseline(self, input_h5: Path, output_h5: Path, _):
        """Baseline: ç¼–è§£ç æµ‹è¯•"""
        events_np = self._load_dsec_events_as_standard(input_h5)

        # Events â†’ Voxel â†’ Events (DSECæ—¶é—´æˆ³æ˜¯Î¼s)
        duration_us = int(events_np[:, 0].max() - events_np[:, 0].min())
        voxel = events_to_voxel(events_np, num_bins=8, sensor_size=(480, 640),
                               fixed_duration_us=duration_us)
        output_events = voxel_to_events(voxel, total_duration=duration_us,
                                       sensor_size=(480, 640))

        # è°ƒæ•´æ—¶é—´èŒƒå›´
        output_events[:, 0] += events_np[:, 0].min()

        self._save_dsec_format_events(output_events, output_h5, input_h5)

    def _load_dsec_events_as_standard(self, dsec_h5: Path) -> np.ndarray:
        """åŠ è½½DSECæ ¼å¼eventså¹¶è½¬æ¢ä¸ºé¡¹ç›®æ ‡å‡†æ ¼å¼ (t,x,y,p)"""
        with h5py.File(dsec_h5, 'r') as f:
            t = f['events/t'][:]
            x = f['events/x'][:]
            y = f['events/y'][:]
            p = f['events/p'][:]

            # DSEC: p=0ä¸ºè´Ÿäº‹ä»¶, p=1ä¸ºæ­£äº‹ä»¶
            # é¡¹ç›®æ ‡å‡†: p=1ä¸ºæ­£äº‹ä»¶, p=-1ä¸ºè´Ÿäº‹ä»¶
            p_standard = np.where(p == 1, 1, -1)

            events = np.column_stack([t, x, y, p_standard])
            return events

    def _save_dsec_format_events(self, events_np: np.ndarray, output_h5: Path,
                                 reference_h5: Path):
        """ä¿å­˜ä¸ºDSECæ ¼å¼events"""
        # è¯»å–å‚è€ƒæ–‡ä»¶çš„t_offset
        with h5py.File(reference_h5, 'r') as f_ref:
            t_offset = f_ref['t_offset'][()]

        # è½¬æ¢ææ€§: -1 â†’ 0
        p_dsec = np.where(events_np[:, 3] == 1, 1, 0).astype(np.uint8)

        with h5py.File(output_h5, 'w') as f:
            events_group = f.create_group('events')

            events_group.create_dataset('t', data=events_np[:, 0].astype(np.int64),
                                       compression='gzip', compression_opts=9)
            events_group.create_dataset('x', data=events_np[:, 1].astype(np.uint16),
                                       compression='gzip', compression_opts=9)
            events_group.create_dataset('y', data=events_np[:, 2].astype(np.uint16),
                                       compression='gzip', compression_opts=9)
            events_group.create_dataset('p', data=p_dsec,
                                       compression='gzip', compression_opts=9)

            f.create_dataset('t_offset', data=t_offset)

    def _convert_dsec_to_standard(self, dsec_h5: Path, standard_h5: Path):
        """è½¬æ¢DSECæ ¼å¼åˆ°é¡¹ç›®æ ‡å‡†æ ¼å¼"""
        events = self._load_dsec_events_as_standard(dsec_h5)

        with h5py.File(standard_h5, 'w') as f:
            events_group = f.create_group('events')
            events_group.create_dataset('t', data=events[:, 0].astype(np.int64),
                                       compression='gzip', compression_opts=9)
            events_group.create_dataset('x', data=events[:, 1].astype(np.uint16),
                                       compression='gzip', compression_opts=9)
            events_group.create_dataset('y', data=events[:, 2].astype(np.uint16),
                                       compression='gzip', compression_opts=9)
            events_group.create_dataset('p', data=events[:, 3].astype(np.int8),
                                       compression='gzip', compression_opts=9)

    def _convert_standard_to_dsec(self, standard_h5: Path, dsec_h5: Path,
                                  reference_h5: Path):
        """è½¬æ¢é¡¹ç›®æ ‡å‡†æ ¼å¼åˆ°DSECæ ¼å¼"""
        events = load_h5_events(str(standard_h5))
        self._save_dsec_format_events(events, dsec_h5, reference_h5)

    def _generate_summary(self):
        """ç”Ÿæˆæ•°æ®é›†æ‘˜è¦"""
        summary_file = self.output_base / 'README.md'

        # ç»Ÿè®¡æ‰€æœ‰å˜ä½“
        variants = sorted(self.output_base.glob(f"{self.sequence_name}_*"))

        with open(summary_file, 'w') as f:
            f.write(f"# TimeLens Dataset - {self.sequence_name}\n\n")
            f.write(f"**æºæ•°æ®**: DSEC - {self.sequence_name}\n")
            f.write(f"**æå–æ—¶é•¿**: {self.duration_s}ç§’\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {Path(__file__).stat().st_mtime}\n\n")

            f.write("## æ•°æ®é›†å˜ä½“\n\n")

            for variant_dir in variants:
                variant_name = variant_dir.name
                events_h5 = variant_dir / 'events/left/events.h5'

                if events_h5.exists():
                    with h5py.File(events_h5, 'r') as h5f:
                        num_events = h5f['events/t'].shape[0]

                    f.write(f"- **{variant_name}**: {num_events:,} events\n")

            f.write("\n## ç›®å½•ç»“æ„\n\n")
            f.write("```\n")
            f.write("sequence_name/\n")
            f.write("â”œâ”€â”€ events/left/\n")
            f.write("â”‚   â””â”€â”€ events.h5\n")
            f.write("â”œâ”€â”€ images/\n")
            f.write("â”‚   â”œâ”€â”€ timestamps.txt\n")
            f.write("â”‚   â””â”€â”€ left/distorted/\n")
            f.write("â”‚       â”œâ”€â”€ 000000.png\n")
            f.write("â”‚       â””â”€â”€ ...\n")
            f.write("```\n")

        print(f"ğŸ“„ æ‘˜è¦æ–‡ä»¶: {summary_file}")


def main():
    parser = argparse.ArgumentParser(description='TimeLensæ•°æ®é›†ç”Ÿæˆå·¥å…·')
    parser.add_argument('--source', type=str,
                       default='/mnt/e/2025/event_flick_flare/object_detection/dsec-det-master/data/train/zurich_city_03_a',
                       help='DSECæºç›®å½•')
    parser.add_argument('--output', type=str, default='timelens',
                       help='è¾“å‡ºåŸºç¡€ç›®å½•')
    parser.add_argument('--duration', type=float, default=2.0,
                       help='æå–æ—¶é•¿ï¼ˆç§’ï¼‰DSEC RGBç›¸æœº20FPSï¼Œ2ç§’=40å¸§')
    parser.add_argument('--debug', action='store_true',
                       help='Debugæ¨¡å¼')

    args = parser.parse_args()

    # åˆ›å»ºç”Ÿæˆå™¨
    generator = TimeLensDatasetGenerator(
        dsec_source_dir=args.source,
        output_base_dir=args.output,
        duration_seconds=args.duration,
        debug=args.debug
    )

    # ç”Ÿæˆæ•°æ®é›†
    generator.generate_all()


if __name__ == '__main__':
    main()
