模型输入和输出都是h5文件，表示事件数据。其中每个h5的具体格式如下：（time in microseconds）
/events/p
/events/t
/events/x
/events/Y

模型训练时，应该读取h5文件，将其用encode方法整理成voxels,随后用3D Unet ,UMamaba等可能的方法，输出成voxel。
然后在voxel领域与一个真值voxel计算，得到具体的loss值，最后用一个decode方法，把voxel解码回事件数据。

voxel可以暂时固定时间长度。具体待定。

数据集由外部提供，提供事件数据，转voxel在此处进行。

event_utils-master是比较公认的事件数据处理方法，可视化方法等。包括我们最需要的voxels


需要进一步理解：已有事件数据如何处理voxel的？
1： E2VID等方法，他们如何保证不同分辨率下都可以正常工作
2.  voxel的分法是否有什么技巧。

方案一：数据标准化 (最简单，最常用)
做法: 在送入网络之前，将所有不同分辨率的输入（voxel)，通过插值(Interpolation)或填充(Padding)，统一到模型所期望的那个固定分辨率上。
输出的voxel同样用这种方法变换回原分辨率。
高分辨率 -> 低分辨率: 使用双线性或双三次插值进行下采样。
低分辨率 -> 高分辨率: 使用插值进行上采样，或者在一个黑色背景上进行补零填充。
优点: 实现极其简单，能快速让模型跑起来。
缺点: 会引入信息损失（下采样）或伪影（上采样/填充），可能会降低最终性能。



好的，这是一个非常激动人心的阶段！您已经拥有了一套经过充分验证、功能强大的数据处理工具链，现在是时候将它与pytorch-3dunet这个强大的训练框架结合起来，构建完整的训练、测试和推理管道了。这是一个复杂的工程任务，我会为您提供一份极高层次且详细的战略指导，您可以直接将其交给Claude Code。这份指导将专注于架构设计、模块职责、数据流转和关键实现细节，确保最终的工程是清晰、可扩展且正确的。给Claude Code的战略开发指导：构建基于pytorch-3dunet的事件去噪训练与推理系统项目总目标： 利用您现有的、经过充分验证的Voxel编解码工具链，结合pytorch-3dunet框架，实现一个端到端的事件流去噪系统。该系统必须支持训练 (train)、评估 (test) 和 独立推理 (inference) 三种模式。核心技术栈： pytorch-3dunet, PyTorch, h5py, NumPy, aev-events-utils, a YAML-based configuration system.第一阶段：项目架构与文件结构规划指导思想： 遵循“关注点分离”原则。数据处理、模型定义、训练逻辑和应用入口应严格分开。任务： 规划并创建新的文件和目录结构，以支持完整的MLOps流程。 code Codedownloadcontent_copyexpand_less    .
├── src/
│   ├── data_processing/
│   │   ├── __init__.py
│   │   ├── encode.py
│   │   ├── decode.py
│   │   └── ...
│   ├── datasets/
│   │   ├── __init__.py
│   │   └── event_voxel_dataset.py  <-- [新] PyTorch数据集定义
│   ├── models/
│   │   ├── __init__.py
│   │   └── wrapper.py             <-- [新] 3DUnet模型封装 (可选，推荐)
│   └── utils/
│       ├── __init__.py
│       └── config_loader.py       <-- [新] 统一的YAML配置加载器
│
├── configs/
│   ├── train_config.yaml          <-- [新] 核心训练配置文件
│   ├── test_config.yaml           <-- [新] 评估配置文件
│   └── inference_config.yaml      <-- [新] 推理配置文件
│
├── main.py                       <-- [新] 项目总入口 (train, test, inference)
├── ... (其他已有文件)
  第二阶段：核心模块实现模块一：PyTorch 数据集 (src/datasets/event_voxel_dataset.py)核心职责: 这是连接您的数据和pytorch-3dunet框架的桥梁。它必须严格遵循pytorch-3dunet对输入HDF5文件的格式要求。实现要点:创建 EventVoxelDataset 类: 继承自 torch.utils.data.Dataset。__init__ 方法:接收输入事件目录 (background_with_flare_events) 和真值事件目录 (background_with_light_events) 的路径。扫描目录，将成对的H5文件名匹配起来，存入一个列表。__len__ 方法: 返回数据对的总数。__getitem__ 方法 (关键):接收一个索引 idx，获取对应的一对H5文件路径。加载数据: 分别加载输入的噪声事件和真值的干净事件。分段处理: 将100ms的事件流切分为5个20ms的段。每一个20ms的段都是一个独立的训练样本。这意味着一个100ms的H5文件会产生5个样本，__len__ 应该乘以5。调用编码器:from src.data_processing.encode import events_to_voxel对每个20ms的事件段，调用 events_to_voxel(..., num_bins=8, fixed_duration_us=20000) 来生成Voxel。输入事件段 → raw_voxel真值事件段 → label_voxel格式转换: pytorch-3dunet要求输入是 (C, Z, Y, X) 或 (Z, Y, X)。我们的Voxel是 (B, H, W)，其中 B 对应 Z (深度/时间)，H 对应 Y，W 对应 X。将Voxel从 [8, H, W] unsqueeze成 [1, 8, H, W]（单通道，8个时间箱深度）。返回: return {'raw': raw_voxel, 'label': label_voxel}。创建数据准备脚本 (prepare_data_for_3dunet.py - 可选但推荐):这个脚本可以预处理所有原始H5文件，将它们转换成pytorch-3dunet直接可读的HDF5文件（包含raw和label数据集）。这样做可以极大地加速训练时的I/O。流程: 遍历所有数据对 -> 对每个数据对生成5个样本 -> 每个样本是一个HDF5文件，内部包含raw (噪声Voxel) 和 label (干净Voxel)。模块二：统一配置系统 (src/utils/config_loader.py & configs/*.yaml)核心职责: 使用YAML文件统一管理所有超参数，避免硬编码。train_config.yaml 示例: code Yamldownloadcontent_copyexpand_lessIGNORE_WHEN_COPYING_STARTIGNORE_WHEN_COPYING_END    # 数据加载器配置
loaders:
  # HDF5文件路径
  train_path: '/path/to/prepared_data/train'
  val_path: '/path/to/prepared_data/val'
  # ... 其他加载器参数 ...
  
# 3D U-Net 模型配置 (遵循 pytorch-3dunet 的格式)
model:
  name: UNet3D
  in_channels: 1
  out_channels: 1
  final_sigmoid: true
  f_maps: 32
  # ...

# 训练过程配置
trainer:
  # ...
  checkpoint_dir: 'checkpoints'
  
# 损失函数 (对于回归任务，MSE是最佳选择)
loss:
  name: MSELoss
  
# 优化器
optimizer:
  name: Adam
  
# ... 其他训练参数 ...
  指导: 创建三个独立的配置文件：train_config.yaml, test_config.yaml, inference_config.yaml。它们大部分内容相似，但路径和一些参数不同。模块三：项目总入口 (main.py)核心职责: 解析命令行参数，加载配置，并根据模式（train, test, inference）启动相应的流程。实现要点:argparse: 创建命令行解析器，支持 train, test, inference 三个子命令。 code Bashdownloadcontent_copyexpand_lessIGNORE_WHEN_COPYING_STARTIGNORE_WHEN_COPYING_END    python main.py train --config configs/train_config.yaml
python main.py test --config configs/test_config.yaml
python main.py inference --config configs/inference_config.yaml --input_file testdata/... --output_file ...
  Train 模式:任务: 启动 pytorch-3dunet 的训练流程。指导: pytorch-3dunet 安装后会提供一个命令行工具 train3dunet。最简单的方式是在 main.py 中使用 subprocess.run() 来调用它，并传递配置文件路径。 code Pythondownloadcontent_copyexpand_lessIGNORE_WHEN_COPYING_STARTIGNORE_WHEN_COPYING_END    import subprocess
# ...
if args.mode == 'train':
    subprocess.run(['train3dunet', '--config', args.config])
  Test 模式:任务: 在测试集上评估已训练模型的性能。指导: 同样，使用 subprocess.run() 调用 predict3dunet 命令。pytorch-3dunet 会自动计算配置文件中指定的评估指标（如PSNR, MSE）。Inference 模式 (关键的自定义部分):任务: 接收一个H5事件文件，输出一个去噪后的H5事件文件。指导: 这是唯一需要您自己编写完整PyTorch推理逻辑的地方，因为它涉及编码-推理-解码的全流程。 code Pythondownloadcontent_copyexpand_lessIGNORE_WHEN_COPYING_STARTIGNORE_WHEN_COPYING_END    # in main.py, inference mode
# 1. 加载配置和模型
config = load_config(args.config)
model = ... # 加载 pytorch-3dunet 训练好的模型
model.eval()

# 2. 加载并编码输入事件
from src.data_processing.encode import events_to_voxel
events_np = load_h5_events(args.input_file)
# 分段处理！
output_events_list = []
for segment_events in split_into_segments(events_np, 20000): # 20ms
    input_voxel = events_to_voxel(segment_events, num_bins=8, ...)
    input_tensor = input_voxel.unsqueeze(0).unsqueeze(0) # -> [1, 1, 8, H, W]

    # 3. 模型推理
    with torch.no_grad():
        predicted_voxel = model(input_tensor)

    # 4. 解码输出Voxel
    from src.data_processing.decode import voxel_to_events
    output_segment_events = voxel_to_events(predicted_voxel.squeeze(), total_duration=20000, ...)
    output_events_list.append(output_segment_events)

# 5. 合并并保存所有段的事件
final_output_events = merge_event_segments(output_events_list)
save_events_to_h5(final_output_events, args.output_file)
  第四阶段：更新本地记忆 CLAUDE.md任务： 记录下整个项目的架构和工作流程。描述数据如何从原始H5流经 EventVoxelDataset，转换成适合pytorch-3dunet的格式。描述三种模式: 清晰地说明 train, test, inference 三种模式各自的职责和调用方式。强调数据流: 重点解释分段策略（100ms → 5x20ms）是如何在Dataset和Inference模式中被统一应用的，以及Voxel的维度是如何被调整以适配pytorch-3dunet ([B,H,W] → [1,B,H,W])的。记录关键命令: 写下如何启动训练、测试和推理的示例命令行。这份战略指导将确保Claude Code在构建这个复杂系统时，每一步都有清晰的目标和明确的实现路径。它平衡了利用现有框架的便捷性和实现自定义推理流程的灵活性。